# Sibyl AI LINE Bot æŠ€è¡“å¯¦ä½œæ–‡æª”

**å°ˆæ¡ˆåç¨±**ï¼šäº”æ¹–åœ’ç”Ÿå‘½æ™ºæ…§åœ’å€ AI LINEBot-Sibyl
**ç‰ˆæœ¬**ï¼š3.4  
**æŠ€è¡“æ¶æ§‹**ï¼šGPT-4o + Google Cloud Platform  
**æ–‡æª”æ—¥æœŸ**ï¼š2025-07-18  
**é–‹ç™¼ç‹€æ…‹**ï¼šæ ¸å¿ƒåŠŸèƒ½å®Œæˆï¼Œé›™æ¨¡å¼ç³»çµ±ç©©å®šé‹è¡Œï¼Œæ¢ä»¶æ€§æ¬„ä½å¯¦ä½œå®Œæˆï¼Œé˜²æ¿«ç”¨æ©Ÿåˆ¶å·²ä¸Šç·š

---

## ç›®éŒ„

1. [ç³»çµ±æ¶æ§‹è¨­è¨ˆ](#ç³»çµ±æ¶æ§‹è¨­è¨ˆ)
2. [æŠ€è¡“æ£§è©³è§£](#æŠ€è¡“æ£§è©³è§£)
3. [æ ¸å¿ƒæ¨¡çµ„è©³è§£](#æ ¸å¿ƒæ¨¡çµ„è©³è§£)
4. [è³‡æ–™åº«è¨­è¨ˆ](#è³‡æ–™åº«è¨­è¨ˆ)
5. [API è¨­è¨ˆèˆ‡æ•´åˆ](#api-è¨­è¨ˆèˆ‡æ•´åˆ)
6. [éƒ¨ç½²èˆ‡ DevOps](#éƒ¨ç½²èˆ‡-devops)
7. [é–‹ç™¼ç’°å¢ƒè¨­å®š](#é–‹ç™¼ç’°å¢ƒè¨­å®š)
8. [ç¨‹å¼ç¢¼è¦ç¯„](#ç¨‹å¼ç¢¼è¦ç¯„)
9. [é‹ç¶­ç›£æ§](#é‹ç¶­ç›£æ§)
10. [æ•…éšœæ’é™¤](#æ•…éšœæ’é™¤)
11. [å®‰å…¨æ€§è¨­è¨ˆ](#å®‰å…¨æ€§è¨­è¨ˆ)
12. [æ•ˆèƒ½å„ªåŒ–](#æ•ˆèƒ½å„ªåŒ–)

---

## ç³»çµ±æ¶æ§‹è¨­è¨ˆ

### æ•´é«”æ¶æ§‹åœ–

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   LINE Platform â”‚â—„â”€â”€â–ºâ”‚   Cloud Run      â”‚â—„â”€â”€â–ºâ”‚  External APIs  â”‚
â”‚                 â”‚    â”‚  (Sibyl AI Bot)  â”‚    â”‚                 â”‚
â”‚   - Webhook     â”‚    â”‚  - FastAPI       â”‚    â”‚  - OpenAI GPT-4oâ”‚
â”‚   - Messaging   â”‚    â”‚  - Python 3.11   â”‚    â”‚  - Embeddings   â”‚
â”‚   - Users       â”‚    â”‚  - Docker        â”‚    â”‚                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                               â”‚                          
                               â–¼                          
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”         
                    â”‚  Google Cloud    â”‚         
                    â”‚   Services       â”‚         
                    â”‚ - Firestore      â”‚         
                    â”‚ - Sheets API     â”‚         
                    â”‚ - Secret Manager â”‚         
                    â”‚ - Cloud Build    â”‚         
                    â”‚ - Artifact Reg   â”‚         
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜         
```

### è³‡æ–™æµå‘è©³è§£

#### 1. è¨Šæ¯æ¥æ”¶æµç¨‹
```
LINE User â†’ LINE Platform â†’ Cloud Run Webhook â†’ message_processor.py
```

#### 2. æ¨¡å¼åˆ¤æ–·æµç¨‹
```
User Message â†’ user_mode_manager.py â†’ Check Mode (Traditional/AI)
```

#### 3. å‚³çµ±æ¨¡å¼æµç¨‹
```
Traditional Mode â†’ auto_reply_handler.py â†’ Keyword Match â†’ Reply
```

#### 4. AI æ¨¡å¼æµç¨‹
```
AI Mode â†’ intent_classifier.py â†’ OpenAI GPT-4o â†’ Intent Result
```

#### 5. ç‹€æ…‹ç®¡ç†æµç¨‹
```
Intent Result â†’ conversation_state.py â†’ Firestore â†’ State Update
```

#### 6. çŸ¥è­˜æª¢ç´¢æµç¨‹
```
Query â†’ retriever.py â†’ Vector Search + Text Search â†’ FAQ Match
```

#### 7. å›æ‡‰ç”Ÿæˆæµç¨‹
```
Context + Query â†’ prompt_builder.py â†’ GPT-4o â†’ Response Generation
```

#### 8. è¨˜æ†¶å„²å­˜æµç¨‹
```
Conversation â†’ memory_manager.py â†’ Firestore â†’ Long-term Storage
```

#### 9. æ—¥èªŒè¨˜éŒ„æµç¨‹
```
All Interactions â†’ sheets_repo.py â†’ Google Sheets â†’ Analytics
```

### æ¶æ§‹è¨­è¨ˆåŸå‰‡

#### å¾®æœå‹™æ¶æ§‹
- **å–®ä¸€è·è²¬**ï¼šæ¯å€‹æ¨¡çµ„è² è²¬ç‰¹å®šåŠŸèƒ½
- **é¬†æ•£è€¦åˆ**ï¼šæ¨¡çµ„é–“é€éæ˜ç¢ºä»‹é¢é€šä¿¡
- **é«˜å…§èš**ï¼šç›¸é—œåŠŸèƒ½èšé›†åœ¨åŒä¸€æ¨¡çµ„

#### é›²ç«¯åŸç”Ÿè¨­è¨ˆ
- **å®¹å™¨åŒ–éƒ¨ç½²**ï¼šDocker + Cloud Run
- **è‡ªå‹•æ“´å±•**ï¼šåŸºæ–¼æµé‡è‡ªå‹•èª¿æ•´è³‡æº
- **ç‹€æ…‹åˆ†é›¢**ï¼šæ‡‰ç”¨é‚è¼¯èˆ‡è³‡æ–™åˆ†é›¢

#### éŒ¯èª¤è™•ç†ç­–ç•¥
- **å„ªé›…é™ç´š**ï¼šAI å¤±æ•—æ™‚å›é€€åˆ° FAQ
- **äººå·¥æ¥ç®¡**ï¼šè¤‡é›œå•é¡Œè‡ªå‹•è½‰æ¥
- **å³æ™‚æ¢å¾©**ï¼šç³»çµ±éŒ¯èª¤æ™‚è‡ªå‹•é‡è©¦

---

## æŠ€è¡“æ£§è©³è§£

### å¾Œç«¯æ¡†æ¶

#### FastAPI é¸æ“‡ç†ç”±
```python
FastAPI å„ªå‹¢:
- é«˜æ•ˆèƒ½: åŸºæ–¼ Starlette + Pydantic
- è‡ªå‹•æ–‡æª”: OpenAPI/Swagger è‡ªå‹•ç”Ÿæˆ
- é¡å‹å®‰å…¨: å®Œæ•´çš„ Type Hints æ”¯æ´
- ç•°æ­¥æ”¯æ´: Native async/await
- å¿«é€Ÿé–‹ç™¼: ç›´è§€çš„ API è¨­è¨ˆ
```

#### æ ¸å¿ƒä¾è³´
```python
# requirements.txt é—œéµå¥—ä»¶
fastapi==0.111.0          # Web æ¡†æ¶
uvicorn[standard]==0.30.0  # ASGI ä¼ºæœå™¨
line-bot-sdk>=3.0.0        # LINE Bot SDK
openai==1.25.0             # OpenAI API
gspread==6.0.2             # Google Sheets
google-auth                # Google èªè­‰
numpy==1.24.3              # å‘é‡é‹ç®—
```

### AI èˆ‡æ©Ÿå™¨å­¸ç¿’

#### OpenAI GPT-4o é…ç½®
```python
# app/config.py
MODEL_NAME = "gpt-4o"
MODEL_TEMPERATURE = 0.85
MODEL_EMBED = "text-embedding-3-large"

# æˆæœ¬è¨­å®š (USD per 1K tokens)
COST_INPUT = 0.0010
COST_OUTPUT = 0.0030

# å®¢æˆ¶ç«¯åˆå§‹åŒ–
openai_client = openai.OpenAI(api_key=OPENAI_API_KEY)
```

#### Embedding å‘é‡è™•ç†
```python
# å‘é‡ç¶­åº¦èˆ‡åˆ†å‰²
EMBEDDING_DIMENSIONS = 3072  # text-embedding-3-large
EMBEDDING_SPLIT_SIZE = 1536  # åˆ†å‰²ç‚ºå…©éƒ¨åˆ†å„²å­˜

# é¤˜å¼¦ç›¸ä¼¼åº¦è¨ˆç®—
def cosine_similarity(vec1, vec2):
    dot_product = np.dot(vec1, vec2)
    norm1 = np.linalg.norm(vec1)
    norm2 = np.linalg.norm(vec2)
    return dot_product / (norm1 * norm2)
```

### è³‡æ–™å„²å­˜æ¶æ§‹

#### Firestore (NoSQL) è¨­è¨ˆ
```javascript
// é›†åˆçµæ§‹
Collections:
- conversation_states     // å°è©±ç‹€æ…‹ç®¡ç†
- recent_conversations   // 30å¤©çŸ­æœŸè¨˜æ†¶
- long_term_memory      // æ°¸ä¹…æ‘˜è¦è¨˜æ†¶

// æ–‡æª” TTL è¨­å®š
TTL_CONVERSATION_STATES = 7 days
TTL_RECENT_CONVERSATIONS = 30 days
TTL_LONG_TERM_MEMORY = permanent
```

#### Google Sheets è³‡æ–™ç®¡ç†
```yaml
Worksheets:
- FAQ:              å•ç­”çŸ¥è­˜åº« + å‘é‡å„²å­˜
- settings:         ç³»çµ±åƒæ•¸é…ç½®
- chat_log:         å°è©±è¨˜éŒ„åˆ†æ
- manual_override:  äººå·¥æ¥ç®¡ç®¡ç†
- holidays:         å‡æœŸè¨­å®š
- admins:           ç®¡ç†å“¡æ¸…å–®
- åŸå§‹è‡ªå‹•å›è¦†:      å‚³çµ±æ¨¡å¼è‡ªå‹•å›è¦†è¨­å®š
```

### éƒ¨ç½²å¹³å°é…ç½®

#### Google Cloud Platform
```yaml
Project Configuration:
- Project ID: bright-gearbox-462803-f5
- Region: asia-east1 (å°ç£)
- Service Account: 487710707313-compute@developer.gserviceaccount.com

Cloud Run Settings:
- CPU: 2 vCPU
- Memory: 2Gi
- Min Instances: 1
- Max Instances: 10
- Concurrency: 50
- Request Timeout: 300s
```

#### ç’°å¢ƒè®Šæ•¸ç®¡ç†
```bash
# å¿…è¦ç’°å¢ƒè®Šæ•¸
SHEET_ID=1_4R_ftouDHhUXygW3ab7YlEzLWbXytwudfOegUIhu5Y
MODEL_NAME=gpt-4o
MODEL_EMBED=text-embedding-3-large
MODEL_TEMPERATURE=0.85

# æª¢ç´¢åƒæ•¸
CONTEXT_K=5
SIM_THRESHOLD=0.50
VECTOR_SIM_THRESHOLD=0.60
WEIGHT_PRIORITY=0.10

# å¿«å–è¨­å®š
FAQ_CACHE_TTL=3600
```

---

## æ ¸å¿ƒæ¨¡çµ„è©³è§£

### 1. è¨Šæ¯è™•ç†å™¨ (message_processor.py)

#### è²¬ä»»éˆè¨­è¨ˆæ¨¡å¼
```python
class MessageProcessor:
    async def process_message(self, event: dict) -> None:
        """ä¸»è¦è™•ç†æµç¨‹"""
        user_id = event["source"]["userId"]
        user_msg = event["message"]["text"]
        reply_token = event["replyToken"]
        
        # 1. ç®¡ç†æŒ‡ä»¤æª¢æŸ¥
        if manual_override_manager.is_admin_command(user_msg):
            manual_override_manager.handle_admin_command(user_id, user_msg)
            return
        
        # 2. äººå·¥æ¥ç®¡ç‹€æ…‹æª¢æŸ¥
        if manual_override_manager.is_in_manual_mode(user_id):
            return
        
        # 3. å°è©±è¨˜æ†¶å„²å­˜
        await memory_manager.save_message(user_id, Message(...))
        
        # 4. ä¸»è¦æ¥­å‹™é‚è¼¯è™•ç†
        await self._handle_user_message(user_id, user_msg, reply_token)
```

#### é›™æ¨¡å¼è™•ç†é‚è¼¯
```python
async def _handle_user_message(self, user_id: str, user_msg: str, reply_token: str):
    """è™•ç†ä½¿ç”¨è€…è¨Šæ¯çš„ä¸»è¦é‚è¼¯"""
    # æª¢æŸ¥ç”¨æˆ¶æ¨¡å¼
    user_mode = await self.user_mode_manager.get_user_mode(user_id)
    
    if user_mode == "traditional":
        # å‚³çµ±æ¨¡å¼è™•ç†
        
        # 1. å„ªå…ˆæª¢æŸ¥ä¸€å¾‹å›æ‡‰
        always_reply = self.auto_reply_handler.find_always_reply()
        if always_reply:
            self._send_auto_reply(always_reply, user_id, user_msg, reply_token, start_time)
            return
            
        # 2. æª¢æŸ¥æ˜¯å¦è¦åˆ‡æ›åˆ° AI æ¨¡å¼
        if user_msg.strip() in ["0", "AIå®¢æœ", "æ™ºæ…§å®¢æœ", "aiå®¢æœ", "AI", "ai"]:
            await self.user_mode_manager.set_user_mode(user_id, "ai")
            # ç™¼é€ AI æ­¡è¿è¨Šæ¯
            return
            
        # 3. å˜—è©¦è‡ªå‹•å›è¦†åŒ¹é…
        auto_reply = self.auto_reply_handler.find_auto_reply(user_msg)
        if auto_reply:
            self._send_auto_reply(auto_reply, user_id, user_msg, reply_token, start_time)
            return
            
        # 4. ç„¡åŒ¹é… - é¡¯ç¤ºå¼•å°è¨Šæ¯
        guide_message = "æŠ±æ­‰ï¼Œæˆ‘ä¸å¤ªç†è§£æ‚¨çš„æ„æ€ã€‚\\n\\næ‚¨å¯ä»¥ï¼š\\n1ï¸âƒ£ è¼¸å…¥æ•¸å­— 1-9 é¸æ“‡æœå‹™\\n0ï¸âƒ£ è¼¸å…¥ 0 ä½¿ç”¨ AI æ™ºæ…§å®¢æœ"
        reply_to_line(reply_token, TextMessage(text=guide_message))
        
    else:  # AI æ¨¡å¼
        # AI æ¨¡å¼ç¾åœ¨æ˜¯æ°¸ä¹…çš„ï¼Œä¸éœ€è¦æ›´æ–°æ´»å‹•æ™‚é–“
        
        # æª¢æŸ¥æ˜¯å¦è¦è¿”å›å‚³çµ±æ¨¡å¼
        if user_msg.strip() in ["è¿”å›", "è¿”å›é¸å–®", "é¸å–®", "å›é¸å–®", "ä¸»é¸å–®"]:
            await self.user_mode_manager.set_user_mode(user_id, "traditional")
            # é¡¯ç¤ºå‚³çµ±é¸å–®æç¤º
            return
            
        # ç¹¼çºŒåŸæœ‰çš„ AI è™•ç†é‚è¼¯...
```

#### è™•ç†æµç¨‹è©³è§£
```python
async def _handle_user_message(self, user_id, user_msg, reply_token):
    """ä¸»è¦æ¥­å‹™é‚è¼¯"""
    # å–å¾—å°è©±è¨˜æ†¶
    memory_context = await memory_manager.format_context_for_prompt(user_id)
    
    # æ„åœ–è­˜åˆ¥
    intent_result = await intent_classifier.classify(user_msg, [])
    
    # æª¢æŸ¥é€²è¡Œä¸­çš„å°è©±ç‹€æ…‹
    active_state = await state_manager.get_active_state(user_id)
    
    if active_state:
        # ç¹¼çºŒå¤šè¼ªå°è©±
        await self._handle_conversation_flow(user_id, user_msg, reply_token, active_state)
    else:
        # æ ¹æ“šæ„åœ–è·¯ç”±
        await self._route_by_intent(intent_result, user_id, user_msg, reply_token, memory_context)
```

### 2. è‡ªå‹•å›è¦†è™•ç†å™¨ (auto_reply_handler.py)

#### åŠŸèƒ½æ¦‚è¿°
è™•ç†å‚³çµ±æ¨¡å¼ä¸‹çš„ç²¾ç¢ºé—œéµå­—åŒ¹é…ï¼Œæ”¯æ´ä¸€å¾‹å›æ‡‰å’Œå¯é»æ“Šåœ–ç‰‡è¨Šæ¯ã€‚

#### ä¸»è¦åŠŸèƒ½
```python
class AutoReplyHandler:
    def find_auto_reply(self, message: str) -> Optional[dict]:
        """ç²¾ç¢ºåŒ¹é…ç”¨æˆ¶è¨Šæ¯"""
        auto_replies = load_auto_replies()
        clean_message = message.strip()
        
        for reply in auto_replies:
            keywords = reply.get('keywords', [])
            for keyword in keywords:
                if clean_message == keyword.strip():
                    return reply
        return None
    
    def find_always_reply(self) -> Optional[dict]:
        """å°‹æ‰¾ä¸€å¾‹å›æ‡‰è¨­å®š"""
        auto_replies = load_auto_replies()
        
        for reply in auto_replies:
            if reply.get('is_always_reply', False) and reply.get('title', '').strip() == 'è‡ªå‹•å›æ‡‰':
                return reply
        return None
    
    def create_clickable_image_template(self, reply_data: dict) -> Optional['TemplateMessage']:
        """å»ºç«‹å¯é»æ“Šçš„åœ–ç‰‡è¨Šæ¯ï¼ˆButtonsTemplateï¼‰"""
        image_url = reply_data.get('template_image_url', '').strip()
        action_url = reply_data.get('template_action_url', '').strip()
        
        if not image_url or not action_url:
            return None
            
        uri_action = create_uri_action(action_label[:20], action_url)
        template = create_buttons_template(
            title=reply_data.get('title', '')[:40],
            text=reply_data.get('template_text', 'é»æ“Šåœ–ç‰‡æŸ¥çœ‹è©³æƒ…')[:60],
            image_url=image_url,
            actions=[uri_action],
            alt_text=reply_data.get('title', 'è«‹æŸ¥çœ‹åœ–ç‰‡')
        )
        return template
```

### 3. ç”¨æˆ¶æ¨¡å¼ç®¡ç†å™¨ (user_mode_manager.py)

#### åŠŸèƒ½æ¦‚è¿°
ç®¡ç†ç”¨æˆ¶åœ¨å‚³çµ±æ¨¡å¼å’Œ AI æ¨¡å¼ä¹‹é–“çš„åˆ‡æ›ï¼Œæ”¯æ´æ°¸ä¹… AI æ¨¡å¼ã€‚

#### ä¸»è¦åŠŸèƒ½
```python
class UserModeManager:
    async def get_user_mode(self, user_id: str) -> str:
        """å–å¾—ç”¨æˆ¶æ¨¡å¼ï¼Œé è¨­ç‚º 'traditional'"""
        # ä¸å†æª¢æŸ¥è¶…æ™‚ï¼ŒAI æ¨¡å¼æ°¸ä¹…ä¿æŒ
        doc_ref = self.db.collection(self.collection_name).document(user_id)
        doc = doc_ref.get()
        
        if doc.exists:
            data = doc.to_dict()
            return data.get('mode', 'traditional')
        return 'traditional'
    
    async def set_user_mode(self, user_id: str, mode: str):
        """è¨­å®šç”¨æˆ¶æ¨¡å¼"""
        doc_ref = self.db.collection(self.collection_name).document(user_id)
        doc_ref.set({
            'mode': mode,
            'last_activity': datetime.utcnow(),
            'updated_at': datetime.utcnow()
        }, merge=True)
```

### 4. æ„åœ–åˆ†é¡å™¨ (intent_classifier.py)

#### æ„åœ–é¡å‹å®šç¾©
```python
class IntentType(Enum):
    PRICE_INQUIRY = "price_inquiry"           # åƒ¹æ ¼è©¢å•
    EVENT_REGISTRATION = "event_registration" # æ³•æœƒå ±å
    ACTIVATION_SERVICE = "activation_service" # å¡”ä½/ç‰Œä½å•Ÿç”¨
    RITUAL_SERVICE = "ritual_service"         # ä½›äº‹ç™»è¨˜
    VISIT_BOOKING = "visit_booking"           # åƒè§€é ç´„
    GENERAL_INQUIRY = "general_inquiry"       # ä¸€èˆ¬è«®è©¢

@dataclass
class IntentResult:
    primary_intent: IntentType
    confidence: float
    extracted_data: Dict[str, any] = None
    sub_type: str = None
    need_human: bool = False
    reason: str = ""
    emotion_tags: List[str] = None  # æ–°å¢ï¼šæƒ…ç·’æ¨™ç±¤
```

#### GPT-4o é©…å‹•çš„åˆ†é¡
```python
class LLMIntentClassifier:
    def __init__(self):
        self.model = MODEL_NAME
        self.system_prompt = self._build_system_prompt()
    
    async def classify(self, message: str, context: List[Dict] = None) -> IntentResult:
        response = openai_client.chat.completions.create(
            model=self.model,
            messages=[
                {"role": "system", "content": self.system_prompt},
                {"role": "user", "content": self._build_user_prompt(message, context)}
            ],
            temperature=0.3,
            response_format={"type": "json_object"}
        )
        
        result = json.loads(response.choices[0].message.content)
        return IntentResult(
            primary_intent=IntentType(result["intent"]),
            confidence=result["confidence"],
            extracted_data=result.get("extracted_data", {}),
            sub_type=result.get("sub_type"),
            need_human=result.get("need_human", False),
            reason=result.get("reason", "")
        )
```

### 3. å°è©±ç‹€æ…‹ç®¡ç† (conversation_state.py)

#### ç‹€æ…‹è³‡æ–™çµæ§‹
```python
@dataclass
class ConversationState:
    user_id: str
    current_intent: str
    current_step: int
    collected_data: Dict[str, any]
    field_sequence: List[str]
    started_at: datetime
    updated_at: datetime
    expires_at: datetime
    # æ–°å¢ï¼šå¾…ç¢ºèªæ„åœ–ç›¸é—œæ¬„ä½
    pending_intent: Optional[str] = None
    pending_data: Optional[Dict[str, any]] = None
    
    def to_dict(self) -> dict:
        return {
            "user_id": self.user_id,
            "current_intent": self.current_intent,
            "current_step": self.current_step,
            "collected_data": self.collected_data,
            "field_sequence": self.field_sequence,
            "started_at": self.started_at,
            "updated_at": self.updated_at,
            "expires_at": self.expires_at,
            "pending_intent": self.pending_intent,
            "pending_data": self.pending_data
        }
```

#### æ¢ä»¶æ€§æ¬„ä½æµç¨‹å®šç¾©
```python
class ConversationFlows:
    # æ³•æœƒå ±åæµç¨‹ï¼ˆåŒ…å«æ¢ä»¶æ€§æ¬„ä½ï¼‰
    EVENT_REGISTRATION = {
        "fields": ["é™½ä¸–å ±åäºº", "å¾€ç”Ÿè©è–©", "å ±åé …ç›®", "é›»è©±", "åœ°å€"],
        "prompts": {
            "é™½ä¸–å ±åäºº": "è«‹å•é™½ä¸–å ±åäººçš„å§“åæ˜¯ï¼Ÿï¼ˆè«‹ä»¥ä¸€äººåšä»£è¡¨ï¼‰",
            "å¾€ç”Ÿè©è–©": "è«‹å•è¦ç‚ºå“ªä½å¾€ç”Ÿè©è–©å ±åå‘¢ï¼Ÿ",
            "å ±åé …ç›®": "è«‹å•è¦å ±åå“ªå€‹æ³•æœƒé …ç›®ï¼Ÿ",
            "é›»è©±": "è«‹æä¾›æ‚¨çš„è¯çµ¡é›»è©±ï¼š",
            "åœ°å€": "è«‹æä¾›æ‚¨çš„åœ°å€ï¼š",
            "æ‹œæ¡Œè™•ç†æ–¹å¼": "è«‹å•æ‹œæ¡Œè¦å¦‚ä½•è™•ç†ï¼Ÿ\n1ï¸âƒ£ ä»£æå‡ºå…¬ç›Šå–®ä½\n2ï¸âƒ£ è‡ªè¡Œå–å›\nè«‹å›è¦† 1 æˆ– 2",
            "æ”¶ä»¶äºº": "è«‹æä¾›æ”¶ä»¶äººå§“åï¼ˆå¯å›è¦†ã€ŒåŒä¸Šã€ä½¿ç”¨å ±åäººè³‡æ–™ï¼‰ï¼š",
            "æ”¶ä»¶äººé›»è©±": "è«‹æä¾›æ”¶ä»¶äººé›»è©±ï¼ˆå¯å›è¦†ã€ŒåŒä¸Šã€ï¼‰ï¼š",
            "æ”¶ä»¶åœ°å€": "è«‹æä¾›æ”¶ä»¶åœ°å€ï¼ˆå¯å›è¦†ã€ŒåŒä¸Šã€ï¼‰ï¼š"
        },
        "conditional_fields": {
            "å ±åé …ç›®": {
                "æ‹œæ¡Œ": ["æ‹œæ¡Œè™•ç†æ–¹å¼"]
            },
            "æ‹œæ¡Œè™•ç†æ–¹å¼": {
                "è¨—é‹å¯„é€": ["æ”¶ä»¶äºº", "æ”¶ä»¶äººé›»è©±", "æ”¶ä»¶åœ°å€"]
            }
        }
    }
    
    # ä½›äº‹ç™»è¨˜æµç¨‹ï¼ˆåŒ…å«æ¢ä»¶æ€§æ¬„ä½ï¼‰
    RITUAL_SERVICE = {
        "fields": ["ç”³è«‹äºº", "å…ˆéˆå§“å", "ä½ç½®ç·¨è™Ÿ", "ä½›äº‹é …ç›®", "ä½›äº‹æ—¥æœŸ", "ä½›äº‹æ™‚é–“"],
        "prompts": {
            "ç”³è«‹äºº": "è«‹å•ç”³è«‹äººçš„å§“åæ˜¯ï¼Ÿ",
            "å…ˆéˆå§“å": "è«‹å•å…ˆéˆçš„å§“åæ˜¯ï¼Ÿ",
            "ä½ç½®ç·¨è™Ÿ": "è«‹æä¾›å¡”ä½æˆ–ç‰Œä½ç·¨è™Ÿï¼š",
            "ä½›äº‹é …ç›®": "è«‹å•è¦è¾¦ç†ä»€éº¼ä½›äº‹ï¼Ÿ",
            "ä½›äº‹æ—¥æœŸ": "è«‹å•å¸Œæœ›çš„ä½›äº‹æ—¥æœŸï¼Ÿï¼ˆä¾‹å¦‚ï¼š12/25ï¼‰",
            "ä½›äº‹æ™‚é–“": "è«‹å•å¸Œæœ›çš„æ™‚é–“ï¼Ÿï¼ˆä¸Šåˆ/ä¸‹åˆï¼‰",
            "å°å¹´è™•ç†æ–¹å¼": "è«‹é¸æ“‡å°å¹´è™•ç†æ–¹å¼ï¼š\n1ï¸âƒ£ å–®ç´”èª¦ç¶“åšå°å¹´\n2ï¸âƒ£ è«‹é¦™ç«å›å®¶\n3ï¸âƒ£ åœ¨å¡”ä¸Šåˆçˆ\nè«‹å›è¦† 1ã€2 æˆ– 3"
        },
        "conditional_fields": {
            "ä½›äº‹é …ç›®": {
                "å°å¹´": ["å°å¹´è™•ç†æ–¹å¼"]
            }
        }
    }
```

#### å‹•æ…‹æ¬„ä½ç®¡ç†å™¨
```python
class ConversationStateManager:
    def __init__(self):
        self.collection = db.collection('conversation_states')
        self.flows = ConversationFlows()
    
    def get_dynamic_fields(self, state: ConversationState) -> List[str]:
        """å–å¾—å‹•æ…‹æ¬„ä½åˆ—è¡¨ï¼ˆåŒ…å«æ¢ä»¶æ€§æ¬„ä½ï¼‰"""
        flow = self.get_flow_for_intent(state.current_intent)
        base_fields = flow["fields"].copy()
        conditional_fields = flow.get("conditional_fields", {})
        
        # éè¿´è™•ç†æ¢ä»¶æ€§æ¬„ä½
        fields_to_add = []
        
        def process_conditional_fields(field_name: str, field_value: str):
            if field_name in conditional_fields:
                conditions = conditional_fields[field_name]
                if field_value in conditions:
                    new_fields = conditions[field_value]
                    for new_field in new_fields:
                        if new_field not in fields_to_add:
                            fields_to_add.append(new_field)
                        # éè¿´è™•ç†å¤šå±¤æ¢ä»¶
                        if new_field in state.collected_data:
                            process_conditional_fields(new_field, state.collected_data[new_field])
        
        # æª¢æŸ¥æ‰€æœ‰å·²æ”¶é›†çš„è³‡æ–™
        for field, value in state.collected_data.items():
            process_conditional_fields(field, value)
        
        # å°‡æ¢ä»¶æ€§æ¬„ä½æ’å…¥åˆ°é©ç•¶ä½ç½®
        if fields_to_add:
            # æ‰¾åˆ°è§¸ç™¼æ¢ä»¶æ¬„ä½çš„ä½ç½®
            for field in fields_to_add:
                if field not in base_fields:
                    base_fields.append(field)
        
        return base_fields
    
    def get_next_field(self, state: ConversationState) -> Optional[str]:
        """å–å¾—ä¸‹ä¸€å€‹è¦æ”¶é›†çš„æ¬„ä½"""
        dynamic_fields = self.get_dynamic_fields(state)
        
        for field in dynamic_fields:
            if field not in state.collected_data:
                return field
        
        return None
    
    async def create_new_state(self, user_id: str, intent: str, initial_data: Dict = None):
        flow = self.get_flow_for_intent(intent)
        now = datetime.now(timezone.utc)
        
        state = ConversationState(
            user_id=user_id,
            current_intent=intent,
            current_step=0,
            collected_data=initial_data or {},
            field_sequence=flow["fields"],  # åŸºç¤æ¬„ä½
            started_at=now,
            updated_at=now,
            expires_at=now + timedelta(days=7)
        )
        
        await self.save_state(state)
        return state
```

### 4. è¨˜æ†¶ç®¡ç†å™¨ (memory_manager.py)

#### é›™å±¤è¨˜æ†¶æ¶æ§‹
```python
class MemoryManager:
    async def save_message(self, user_id: str, message: Message, context: ConversationContext = None):
        """å„²å­˜è¨Šæ¯åˆ°çŸ­æœŸè¨˜æ†¶"""
        doc_ref = self.db.collection(RECENT_CONVERSATIONS).document(user_id)
        
        current_time = datetime.now(timezone.utc)
        expire_time = current_time + timedelta(days=SHORT_TERM_DAYS)
        
        # æ›´æ–°æˆ–å»ºç«‹è¨˜æ†¶æ–‡ä»¶
        if doc.exists:
            data = doc.to_dict()
            messages = data.get("messages", [])
            messages.append(message.to_dict())
            doc_ref.update({
                "messages": messages,
                "last_activity": current_time,
                "expires_at": expire_time
            })
        else:
            data = {
                "user_id": user_id,
                "messages": [message.to_dict()],
                "context": context.to_dict() if context else {},
                "created_at": current_time,
                "last_activity": current_time,
                "expires_at": expire_time
            }
            doc_ref.set(data)
```

#### è¨˜æ†¶æ ¼å¼åŒ–
```python
async def format_context_for_prompt(self, user_id: str) -> str:
    """æ ¼å¼åŒ–è¨˜æ†¶ä¾› GPT ä½¿ç”¨"""
    recent_messages = await self.get_recent_messages(user_id)
    context = await self.get_conversation_context(user_id)
    long_term = await self.get_long_term_memory(user_id)
    
    prompt_parts = []
    
    # é•·æœŸè¨˜æ†¶æ‘˜è¦
    if long_term and "important_people" in long_term:
        prompt_parts.append("ã€è¨˜å¾—çš„é‡è¦äººç‰©ã€‘")
        for name, info in long_term["important_people"].items():
            relationship = info.get("relationship", "")
            memories = ", ".join(info.get("key_memories", []))
            prompt_parts.append(f"- {name}ï¼ˆ{relationship}ï¼‰ï¼š{memories}")
    
    # æœ€è¿‘å°è©±
    if recent_messages:
        prompt_parts.append("\nã€æœ€è¿‘çš„å°è©±ã€‘")
        for msg in recent_messages[-10:]:
            role = "å®¢æˆ¶" if msg.role == "user" else "ä½ "
            content = msg.content[:100] + "..." if len(msg.content) > 100 else msg.content
            prompt_parts.append(f"{role}ï¼š{content}")
    
    return "\n".join(prompt_parts) if prompt_parts else ""
```

### 5. æ¬„ä½é©—è­‰å™¨ (field_validator.py)

#### åŠŸèƒ½æ¦‚è¿°
æä¾›å³æ™‚çš„æ¬„ä½æ ¼å¼é©—è­‰å’ŒéŒ¯èª¤æç¤ºï¼Œæ”¯æ´æ¢ä»¶æ€§æ¬„ä½å’Œéš±è—é¸é …è™•ç†ã€‚

#### ä¸»è¦åŠŸèƒ½
```python
class FieldValidator:
    """æ¬„ä½é©—è­‰å™¨"""
    
    def validate_field(self, field_name: str, value: str, context: dict = None) -> Tuple[bool, str, Any]:
        """
        é©—è­‰æ¬„ä½å€¼
        
        Returns:
            (æ˜¯å¦é€šé, éŒ¯èª¤è¨Šæ¯, æ ¼å¼åŒ–å¾Œçš„å€¼)
        """
        # æª¢æŸ¥æ˜¯å¦ä½¿ç”¨ã€ŒåŒä¸Šã€
        if value.strip().lower() in ["åŒä¸Š", "ä¸€æ¨£", "ç›¸åŒ", "åŒ", "same"]:
            return self._handle_same_as_above(field_name, context)
        
        # æ ¹æ“šæ¬„ä½åç¨±èª¿ç”¨å°æ‡‰çš„é©—è­‰æ–¹æ³•
        validators = {
            "é›»è©±": self.validate_phone,
            "æ”¶ä»¶äººé›»è©±": self.validate_phone,
            "æ‹œæ¡Œè™•ç†æ–¹å¼": self.validate_table_option,
            "å°å¹´è™•ç†æ–¹å¼": self.validate_year_option,
            # ... æ›´å¤šé©—è­‰å™¨
        }
        
        validator = validators.get(field_name, self.validate_generic)
        return validator(value, context)
```

#### éš±è—é¸é …è™•ç†
```python
def validate_table_option(self, value: str, context: dict = None) -> Tuple[bool, str, str]:
    """é©—è­‰æ‹œæ¡Œè™•ç†æ–¹å¼"""
    # æª¢æŸ¥æ˜¯å¦ä¸»å‹•è¦æ±‚è¨—é‹ï¼ˆéš±è—é¸é …ï¼‰
    shipping_keywords = ["è¨—é‹", "å¯„é€", "å¯„å›", "å®…é…", "è²¨é‹", "é‹é€", "éƒµå¯„"]
    if any(keyword in value for keyword in shipping_keywords):
        return True, "", "è¨—é‹å¯„é€"
    
    # æ¨™æº–é¸é …è™•ç†
    standard_mappings = {
        "1": "ä»£æå‡ºå…¬ç›Šå–®ä½",
        "2": "è‡ªè¡Œå–å›",
        "ä»£æ": "ä»£æå‡ºå…¬ç›Šå–®ä½",
        "è‡ªå–": "è‡ªè¡Œå–å›"
    }
    
    if value in standard_mappings:
        return True, "", standard_mappings[value]
    
    # é©—è­‰å¤±æ•—æ™‚ï¼Œåªé¡¯ç¤ºå…©å€‹é¸é …ï¼ˆä¸é¡¯ç¤ºè¨—é‹ï¼‰
    error_msg = "è«‹é¸æ“‡æ‹œæ¡Œè™•ç†æ–¹å¼ï¼š\n"
    error_msg += "1ï¸âƒ£ ä»£æå‡ºå…¬ç›Šå–®ä½\n"
    error_msg += "2ï¸âƒ£ è‡ªè¡Œå–å›\n"
    error_msg += "è«‹å›è¦† 1 æˆ– 2"
    
    return False, error_msg, value
```

#### åŒä¸ŠåŠŸèƒ½å¯¦ç¾
```python
def _handle_same_as_above(self, field_name: str, context: dict) -> Tuple[bool, str, Any]:
    """è™•ç†ã€ŒåŒä¸Šã€çš„æƒ…æ³"""
    # å°æ‡‰é—œä¿‚
    mapping = {
        "æ”¶ä»¶äºº": "é™½ä¸–å ±åäºº",
        "æ”¶ä»¶äººé›»è©±": "é›»è©±",
        "æ”¶ä»¶åœ°å€": "åœ°å€"
    }
    
    source_field = mapping.get(field_name)
    if source_field and context and source_field in context:
        source_value = context[source_field]
        return True, "", source_value
    
    # æ‰¾ä¸åˆ°å°æ‡‰è³‡æ–™
    return False, f"æ‰¾ä¸åˆ°å¯åƒç…§çš„{field_name}è³‡æ–™ï¼Œè«‹ç›´æ¥è¼¸å…¥", ""
```

### 6. é€²åº¦æ ¼å¼åŒ–å™¨ (progress_formatter.py)

#### åŠŸèƒ½æ¦‚è¿°
æä¾›æ¸…æ™°çš„é€²åº¦é¡¯ç¤ºå’Œå¼•å°ï¼Œæ”¯æ´å‹•æ…‹æ¬„ä½è¨ˆç®—å’Œæ¢ä»¶æ€§æ¬„ä½é¡¯ç¤ºã€‚

#### å‹•æ…‹é€²åº¦è¨ˆç®—
```python
class ProgressFormatter:
    """é€²åº¦æ ¼å¼åŒ–å™¨"""
    
    def format_progress(self, state: ConversationState, error_field: str = None) -> str:
        """æ ¼å¼åŒ–é€²åº¦é¡¯ç¤º"""
        # å–å¾—ç¸½æ¬„ä½æ•¸ï¼ˆåŒ…å«æ¢ä»¶æ€§æ¬„ä½ï¼‰
        total_fields = self._get_total_fields(state)
        completed = len(state.collected_data)
        remaining = total_fields - completed
        
        # å»ºç«‹é€²åº¦æ¢
        progress_bar = self._create_progress_bar(completed, total_fields)
        
        # é¡¯ç¤ºå·²æ”¶é›†å’Œå¾…å¡«å¯«çš„è³‡æ–™
        message = f"{self.EMOJI['progress']} ã€{flow_name}é€²åº¦ã€‘\n"
        message += f"{progress_bar}\n"
        message += f"å·²å®Œæˆ {completed}/{total_fields} é …\n\n"
        
        return message
    
    def _get_total_fields(self, state: ConversationState) -> int:
        """è¨ˆç®—ç¸½æ¬„ä½æ•¸ï¼ˆåŒ…å«å¤šå±¤æ¢ä»¶æ€§æ¬„ä½ï¼‰"""
        from app.conversation_state import get_state_manager
        state_manager = get_state_manager()
        
        # ä½¿ç”¨å‹•æ…‹æ¬„ä½åˆ—è¡¨
        dynamic_fields = state_manager.get_dynamic_fields(state)
        return len(dynamic_fields)
```

#### å®Œæˆæ‘˜è¦æ ¼å¼åŒ–
```python
def _format_event_registration_summary(self, data: Dict) -> str:
    """æ ¼å¼åŒ–æ³•æœƒå ±åæ‘˜è¦"""
    # åŸºæœ¬å ±åè³‡è¨Š
    summary = f"ğŸ“¿ å ±åé …ç›®ï¼š{data.get('å ±åé …ç›®', '')}\n"
    summary += f"ğŸ‘¤ é™½ä¸–å ±åäººï¼š{data.get('é™½ä¸–å ±åäºº', '')}\n"
    summary += f"ğŸ™ å¾€ç”Ÿè©è–©ï¼š{data.get('å¾€ç”Ÿè©è–©', '')}\n"
    summary += f"ğŸ“ è¯çµ¡é›»è©±ï¼š{data.get('é›»è©±', '')}\n"
    summary += f"ğŸ  è¯çµ¡åœ°å€ï¼š{data.get('åœ°å€', '')}\n"
    
    # æ‹œæ¡Œè™•ç†æ–¹å¼
    if data.get('å ±åé …ç›®') == 'æ‹œæ¡Œ' and 'æ‹œæ¡Œè™•ç†æ–¹å¼' in data:
        summary += f"ğŸ“¦ æ‹œæ¡Œè™•ç†ï¼š{data['æ‹œæ¡Œè™•ç†æ–¹å¼']}"
        
        # è¨—é‹è³‡è¨Šæ”¾åœ¨æœ€å¾Œ
        if data['æ‹œæ¡Œè™•ç†æ–¹å¼'] == 'è¨—é‹å¯„é€':
            summary += f"\n\nã€è¨—é‹è³‡è¨Šã€‘\n"
            summary += f"ğŸ‘¤ æ”¶ä»¶äººï¼š{data.get('æ”¶ä»¶äºº', '')}\n"
            summary += f"ğŸ“ æ”¶ä»¶é›»è©±ï¼š{data.get('æ”¶ä»¶äººé›»è©±', '')}\n"
            summary += f"ğŸ“ æ”¶ä»¶åœ°å€ï¼š{data.get('æ”¶ä»¶åœ°å€', '')}"
    
    return summary
```

### 7. æª¢ç´¢ç³»çµ± (retriever.py)

#### æ··åˆæª¢ç´¢æ¶æ§‹
```python
def retrieve(user_text: str) -> Tuple[Optional[dict], float]:
    """æ··åˆæª¢ç´¢ä¸»å‡½æ•¸"""
    faq_list = load_faq()
    result = None
    
    # å„ªå…ˆä½¿ç”¨å‘é‡æª¢ç´¢
    if USE_VECTOR_SEARCH:
        result = _vector_search(user_text, faq_list)
        
        # å‘é‡æª¢ç´¢å¤±æ•—å‰‡é€€å›æ–‡å­—æª¢ç´¢
        if not result:
            result = _text_search(user_text, faq_list)
    else:
        result = _text_search(user_text, faq_list)
    
    if result:
        return result.item, round(result.score, 2)
    
    return None, 0.0
```

#### å‘é‡æª¢ç´¢å¯¦ç¾
```python
def _vector_search(query: str, faq_list: List[dict]) -> Optional[SearchResult]:
    """å‘é‡èªç¾©æª¢ç´¢"""
    query_vec = _get_embedding(query)
    if query_vec is None:
        return None
    
    best_result = None
    best_score = 0.0
    
    for row in faq_list:
        # å¾åˆ†å‰²å‘é‡é‡å»ºå®Œæ•´å‘é‡
        faq_vec = _parse_split_embedding(row)
        if faq_vec is None:
            continue
        
        # è¨ˆç®—ç›¸ä¼¼åº¦
        similarity = _cosine_similarity(query_vec, faq_vec)
        
        # åŠ å…¥å„ªå…ˆæ¬Šé‡
        weighted_score = similarity * (1 + (row["priority"] - 1) * WEIGHT_PRIORITY)
        
        if weighted_score > best_score:
            best_score = weighted_score
            best_result = SearchResult(
                item=row,
                score=weighted_score,
                method="vector"
            )
    
    return best_result if best_result and best_result.score >= VECTOR_SIM_THRESHOLD else None
```

#### å‘é‡åˆ†å‰²è™•ç†
```python
def _parse_split_embedding(row: dict) -> Optional[np.ndarray]:
    """é‡å»ºåˆ†å‰²å„²å­˜çš„å‘é‡"""
    try:
        part1_str = row.get("embedding_part1", "").strip()
        part2_str = row.get("embedding_part2", "").strip()
        
        if not part1_str or not part2_str:
            return None
        
        part1 = json.loads(part1_str)
        part2 = json.loads(part2_str)
        full_vector = part1 + part2
        
        return np.array(full_vector)
    except (json.JSONDecodeError, ValueError, TypeError) as e:
        logging.warning(f"Error parsing split embedding: {e}")
        return None
```

---

## è³‡æ–™åº«è¨­è¨ˆ

### Firestore é›†åˆè¨­è¨ˆ

#### conversation_states é›†åˆ
```javascript
// æ–‡æª”çµæ§‹
{
  "user_id": "LINE_USER_ID",
  "current_intent": "event_registration",
  "current_step": 2,
  "collected_data": {
    "é™½ä¸–å ±åäºº": "ç‹å°æ˜",
    "å¾€ç”Ÿè©è–©": "ç‹è€å¤ªå¤ª"
  },
  "field_sequence": ["é™½ä¸–å ±åäºº", "å¾€ç”Ÿè©è–©", "å ±åé …ç›®", "é›»è©±", "åœ°å€"],
  "started_at": "2025-07-10T10:00:00Z",
  "updated_at": "2025-07-10T10:05:00Z",
  "expires_at": "2025-07-17T10:00:00Z"
}

// ç´¢å¼•è¨­è¨ˆ
- user_id (å–®ä¸€æ¬„ä½ç´¢å¼•)
- expires_at (TTL ç´¢å¼•)
```

#### recent_conversations é›†åˆ
```javascript
// æ–‡æª”çµæ§‹
{
  "user_id": "LINE_USER_ID",
  "messages": [
    {
      "role": "user",
      "content": "æˆ‘æƒ³äº†è§£å¡”ä½åƒ¹æ ¼",
      "timestamp": "2025-07-10T10:00:00Z",
      "emotion_tags": ["inquiry"]
    },
    {
      "role": "assistant", 
      "content": "å¡”ä½åƒ¹æ ¼8è¬å…ƒèµ·...",
      "timestamp": "2025-07-10T10:00:03Z"
    }
  ],
  "context": {
    "mentioned_people": {
      "åª½åª½": "æ¯è¦ª"
    },
    "key_events": ["åƒ¹æ ¼è©¢å•"],
    "emotional_state": "å¹³éœè©¢å•"
  },
  "created_at": "2025-07-10T10:00:00Z",
  "last_activity": "2025-07-10T10:00:03Z",
  "expires_at": "2025-08-09T10:00:00Z"  // 30å¤©å¾ŒéæœŸ
}

// ç´¢å¼•è¨­è¨ˆ
- user_id (å–®ä¸€æ¬„ä½ç´¢å¼•)
- expires_at (TTL ç´¢å¼•)
- last_activity (æ’åºç´¢å¼•)
```

#### long_term_memory é›†åˆ
```javascript
// æ–‡æª”çµæ§‹
{
  "user_id": "LINE_USER_ID",
  "important_people": {
    "ç‹è€å¤ªå¤ª": {
      "relationship": "æ¯è¦ª",
      "key_memories": ["è©¢å•å¡”ä½åƒ¹æ ¼", "2024å¹´å¾€ç”Ÿ"],
      "last_mentioned": "2025-07-10T10:00:00Z"
    }
  },
  "emotional_journey": [
    {
      "date": "2025-07-10",
      "summary": "åˆæ¬¡è©¢å•å¡”ä½ï¼Œæƒ…ç·’å¹³ç©©",
      "dominant_emotion": "å¹³éœ"
    }
  ],
  "service_history": [
    {
      "date": "2025-07-10",
      "service_type": "price_inquiry",
      "completed": true
    }
  ],
  "created_at": "2025-07-10T10:00:00Z",
  "updated_at": "2025-07-10T10:00:03Z"
}

// ç´¢å¼•è¨­è¨ˆ
- user_id (å–®ä¸€æ¬„ä½ç´¢å¼•)
- updated_at (æ’åºç´¢å¼•)
```

### Google Sheets è³‡æ–™çµæ§‹

#### FAQ å·¥ä½œè¡¨
```
æ¬„ä½è¨­è¨ˆ:
A: id                   // å”¯ä¸€è­˜åˆ¥ç¢¼
B: category            // åˆ†é¡
C: question            // ä¸»è¦å•é¡Œ
D: variants            // è®Šé«”å•æ³• (æ›è¡Œåˆ†éš”)
E: answer              // å›ç­”å…§å®¹
F: media_urls          // åª’é«”é€£çµ (æ›è¡Œåˆ†éš”)
G: priority            // å„ªå…ˆç´š (1-5)
H: is_active           // æ˜¯å¦å•Ÿç”¨ (TRUE/FALSE)
I: valid_from          // ç”Ÿæ•ˆæ—¥æœŸ
J: valid_to            // å¤±æ•ˆæ—¥æœŸ
K: embedding_part1     // å‘é‡å‰åŠéƒ¨ (JSON)
L: embedding_part2     // å‘é‡å¾ŒåŠéƒ¨ (JSON)
M: embedding_ts        // å‘é‡ç”Ÿæˆæ™‚é–“
N: updated_at          // æœ€å¾Œæ›´æ–°æ™‚é–“
```

#### settings å·¥ä½œè¡¨
```
æ¬„ä½è¨­è¨ˆ:
A: key                 // è¨­å®šéµ
B: value               // è¨­å®šå€¼

ç¯„ä¾‹å…§å®¹:
prompt_template        // æç¤ºè©æ¨¡æ¿
sim_threshold         // ç›¸ä¼¼åº¦é–€æª»
vector_sim_threshold  // å‘é‡ç›¸ä¼¼åº¦é–€æª»
use_vector_search     // æ˜¯å¦ä½¿ç”¨å‘é‡æª¢ç´¢
manual_override_ttl_hours // äººå·¥æ¥ç®¡TTLå°æ™‚æ•¸
```

#### chat_log å·¥ä½œè¡¨
```
æ¬„ä½è¨­è¨ˆ:
A: timestamp          // æ™‚é–“æˆ³è¨˜
B: user_id           // ä½¿ç”¨è€…ID
C: user_message      // ä½¿ç”¨è€…è¨Šæ¯
D: matched_id        // åŒ¹é…çš„FAQ ID
E: score             // ç›¸ä¼¼åº¦åˆ†æ•¸
F: bot_response      // æ©Ÿå™¨äººå›æ‡‰
G: media             // åª’é«”é€£çµ
H: model             // ä½¿ç”¨çš„AIæ¨¡å‹
I: prompt_tokens     // è¼¸å…¥tokenæ•¸
J: completion_tokens // è¼¸å‡ºtokenæ•¸
K: cost_usd          // æˆæœ¬(ç¾å…ƒ)
L: response_time_ms  // å›æ‡‰æ™‚é–“(æ¯«ç§’)
```

#### åŸå§‹è‡ªå‹•å›è¦†å·¥ä½œè¡¨
```
æ¬„ä½è¨­è¨ˆ:
A: æ¨™é¡Œ               // é¡¯ç¤ºåç¨±
B: å…§å®¹               // å›è¦†æ–‡å­—å…§å®¹ï¼ˆæ”¯æ´ [split] åˆ†éš”ï¼‰
C: å›æ‡‰é¡å‹           // "é—œéµå­—å›æ‡‰:" æˆ– "ä¸€å¾‹å›æ‡‰"
D: å›æ‡‰åœ–ç‰‡1-4        // åœ–ç‰‡ URLï¼ˆæœ€å¤š 4 å¼µï¼‰
H: æ¨¡æ¿åœ–ç‰‡           // å¯é»æ“Šåœ–ç‰‡ URL
I: é»æ“Šé€£çµ           // é»æ“Šå¾Œå°å‘çš„ HTTPS ç¶²å€
J: æŒ‰éˆ•æ–‡å­—           // æŒ‰éˆ•é¡¯ç¤ºæ–‡å­—ï¼ˆæœ€å¤š 20 å­—ï¼‰
K: æ¨¡æ¿èªªæ˜           // åœ–ç‰‡ä¸‹æ–¹èªªæ˜ï¼ˆæœ€å¤š 60 å­—ï¼‰

ç‰¹æ®Šè¨­å®š:
- ä¸€å¾‹å›æ‡‰ï¼šæ¨™é¡Œç‚ºã€Œè‡ªå‹•å›æ‡‰ã€ä¸”å›æ‡‰é¡å‹åŒ…å«ã€Œä¸€å¾‹å›æ‡‰ã€
- é—œéµå­—æ ¼å¼ï¼šåœ¨ã€Œé—œéµå­—å›æ‡‰:ã€å¾Œæ›è¡Œåˆ†éš”å¤šå€‹é—œéµå­—
- åœ–ç‰‡ç›´éˆï¼šå›æ‡‰åœ–ç‰‡1-4 æ”¯æ´ HTTPS åœ–ç‰‡ç›´éˆï¼ˆimgurã€åœ–åºŠã€CDN ç­‰ï¼‰

åœ–ç‰‡è¦æ±‚:
- å¿…é ˆä½¿ç”¨ HTTPS å”å®š
- å¿…é ˆç‚ºå…¬é–‹å¯å­˜å–çš„ç›´æ¥é€£çµ
- æ”¯æ´æ ¼å¼ï¼šJPEGã€PNG
- æª”æ¡ˆå¤§å°ï¼šæœ€å¤§ 10MB
- åœ–ç‰‡å°ºå¯¸ï¼šæœ€å¤§ 1024x1024 åƒç´ 
```

---

## API è¨­è¨ˆèˆ‡æ•´åˆ

### FastAPI è·¯ç”±è¨­è¨ˆ

#### ä¸»è¦ç«¯é»
```python
# app/main.py
@app.get("/")
async def root():
    """å¥åº·æª¢æŸ¥ç«¯é»"""
    return {
        "service": "Sibyl AI LINE Bot",
        "status": "active",
        "version": "3.0",
        "model": MODEL_NAME
    }

@app.get("/health")
async def health_check():
    """è©³ç´°å¥åº·æª¢æŸ¥"""
    health_status = {
        "status": "healthy",
        "checks": {
            "openai": False,
            "sheets": False,
            "firestore": False
        }
    }
    # æª¢æŸ¥å„æœå‹™ç‹€æ…‹...
    return health_status

@app.post("/webhook")
async def webhook(req: Request):
    """LINE Webhook ç«¯é»"""
    return await handle_line_webhook(req)
```

#### Webhook è™•ç†æµç¨‹
```python
# app/line_handler.py
async def handle_line_webhook(request: Request):
    """è™•ç† LINE webhook è«‹æ±‚"""
    # 1. é©—è­‰ç°½å
    signature = request.headers.get('X-Line-Signature')
    body_bytes = await request.body()
    
    if not _verify_signature(body_bytes, signature):
        raise HTTPException(status_code=403, detail="Invalid signature")
    
    # 2. è§£æè«‹æ±‚
    body_json = json.loads(body_bytes.decode('utf-8'))
    
    # 3. æª¢æŸ¥äººå·¥æ¥ç®¡TTL
    manual_override_manager.check_ttl()
    
    # 4. è™•ç†äº‹ä»¶
    events = body_json.get("events", [])
    tasks = []
    
    for event in events:
        if event.get("type") == "message" and event["message"].get("type") == "text":
            task = asyncio.create_task(_process_event(event))
            tasks.append(task)
    
    if tasks:
        await asyncio.gather(*tasks, return_exceptions=True)
    
    return {"status": "ok"}
```

### LINE Bot SDK æ•´åˆ

#### è¨Šæ¯å›è¦†å°è£
```python
# app/line_utils.py
from linebot.v3.messaging import (
    ApiClient, MessagingApi, Configuration,
    ReplyMessageRequest, TextMessage, ImageMessage
)

# åˆå§‹åŒ– LINE Bot API
configuration = Configuration(access_token=LINE_CHANNEL_ACCESS_TOKEN)
api_client = ApiClient(configuration)
line_bot_api = MessagingApi(api_client)

def reply_to_line(reply_token: str, messages: Union[Message, List[Message]]) -> bool:
    """å›è¦†è¨Šæ¯åˆ° LINE"""
    if not isinstance(messages, list):
        messages = [messages]
    
    # LINE é™åˆ¶æœ€å¤š 5 å‰‡è¨Šæ¯
    if len(messages) > 5:
        messages = messages[:5]
    
    try:
        reply_request = ReplyMessageRequest(
            reply_token=reply_token,
            messages=messages
        )
        line_bot_api.reply_message(reply_request)
        return True
    except Exception as e:
        logger.error(f"Failed to reply to LINE: {e}")
        return False
```

#### å¤šåª’é«”è¨Šæ¯è™•ç†
```python
def create_text_messages(text: str, split_token: str = "[split]") -> List[TextMessage]:
    """å»ºç«‹æ–‡å­—è¨Šæ¯ï¼Œæ”¯æ´åˆ†å‰²"""
    if not text:
        return []
    
    text_parts = text.split(split_token)
    messages = []
    
    for part in text_parts:
        part = part.strip()
        if part:
            messages.append(TextMessage(text=part))
    
    return messages

def combine_messages(text: str = None, image_urls: List[str] = None) -> List[Message]:
    """çµ„åˆæ–‡å­—å’Œåœ–ç‰‡è¨Šæ¯"""
    messages = []
    
    if text:
        messages.extend(create_text_messages(text))
    
    if image_urls:
        for url in image_urls:
            if url and url.strip():
                messages.append(ImageMessage(
                    original_content_url=url.strip(),
                    preview_image_url=url.strip()
                ))
    
    return messages[:5]  # LINE é™åˆ¶
```

### OpenAI API æ•´åˆ

#### å®¢æˆ¶ç«¯é…ç½®
```python
# app/config.py
import openai

# åˆå§‹åŒ–å®¢æˆ¶ç«¯
openai_client = openai.OpenAI(api_key=OPENAI_API_KEY)

# GPT-4o èª¿ç”¨å°è£
async def call_gpt4o(messages: List[dict], temperature: float = MODEL_TEMPERATURE) -> dict:
    """GPT-4o API èª¿ç”¨å°è£"""
    try:
        response = openai_client.chat.completions.create(
            model=MODEL_NAME,
            messages=messages,
            temperature=temperature,
            response_format={"type": "json_object"} if "json" in messages[0]["content"].lower() else None
        )
        return response
    except Exception as e:
        logger.error(f"OpenAI API error: {e}")
        raise
```

#### Embedding API ä½¿ç”¨
```python
def get_embedding(text: str) -> Optional[np.ndarray]:
    """å–å¾—æ–‡å­—å‘é‡"""
    try:
        response = openai_client.embeddings.create(
            input=text,
            model=MODEL_EMBED
        )
        return np.array(response.data[0].embedding)
    except Exception as e:
        logger.error(f"Embedding API error: {e}")
        return None
```

### Google Cloud æœå‹™æ•´åˆ

#### Secret Manager æ•´åˆ
```python
# é‡‘é‘°ç®¡ç†
from google.cloud import secretmanager

def get_secret(secret_id: str, project_id: str) -> str:
    """å¾ Secret Manager å–å¾—é‡‘é‘°"""
    client = secretmanager.SecretManagerServiceClient()
    name = f"projects/{project_id}/secrets/{secret_id}/versions/latest"
    response = client.access_secret_version(request={"name": name})
    return response.payload.data.decode("UTF-8")
```

#### Firestore é€£æ¥
```python
# Firestore å®¢æˆ¶ç«¯
from google.cloud import firestore

# ä½¿ç”¨ ADC (Application Default Credentials)
db = firestore.Client()

# ç•°æ­¥æ“ä½œå°è£
async def firestore_get(collection: str, document: str) -> dict:
    """ç•°æ­¥å–å¾—æ–‡æª”"""
    return await asyncio.to_thread(
        lambda: db.collection(collection).document(document).get().to_dict()
    )

async def firestore_set(collection: str, document: str, data: dict):
    """ç•°æ­¥è¨­å®šæ–‡æª”"""
    await asyncio.to_thread(
        lambda: db.collection(collection).document(document).set(data)
    )
```

---

## éƒ¨ç½²èˆ‡ DevOps

### Docker å®¹å™¨åŒ–

#### Dockerfile è¨­è¨ˆ
```dockerfile
FROM python:3.11-slim

# è¨­å®šå·¥ä½œç›®éŒ„
WORKDIR /app

# è¤‡è£½ä¾è³´æ–‡ä»¶
COPY requirements.txt .

# å®‰è£ä¾è³´å¥—ä»¶
RUN pip install --no-cache-dir -r requirements.txt

# è¤‡è£½æ‡‰ç”¨ç¨‹å¼ç¨‹å¼ç¢¼
COPY ./app/ ./app

# æš´éœ²ç«¯å£
EXPOSE 8080

# å•Ÿå‹•æŒ‡ä»¤
CMD ["uvicorn", "app.main:app", "--host", "0.0.0.0", "--port", "8080"]
```

#### .dockerignore è¨­å®š
```
# .dockerignore
__pycache__/
*.pyc
*.pyo
*.pyd
.Python
env/
venv/
.env
.git/
.gitignore
README.md
Dockerfile
.dockerignore
```

### Cloud Build CI/CD

#### cloudbuild.yaml é…ç½®
```yaml
# cloudbuild.yaml
steps:
  # å–å¾— Git commit SHA
  - name: 'gcr.io/cloud-builders/git'
    id: 'Get commit SHA'
    entrypoint: 'sh'
    args:
    - '-c'
    - |
      SHORT_SHA=$(git rev-parse --short HEAD)
      echo $SHORT_SHA > /workspace/short_sha.txt

  # å»ºç½® Docker æ˜ åƒ
  - name: 'gcr.io/cloud-builders/docker'
    id: 'Build Docker image'
    entrypoint: 'sh'
    args:
    - '-c'
    - |
      SHORT_SHA=$(cat /workspace/short_sha.txt)
      docker build \
        --no-cache \
        --tag asia-east1-docker.pkg.dev/bright-gearbox-462803-f5/linebot-repo/linebot:$SHORT_SHA \
        --tag asia-east1-docker.pkg.dev/bright-gearbox-462803-f5/linebot-repo/linebot:latest \
        .

  # æ¨é€åˆ° Artifact Registry
  - name: 'gcr.io/cloud-builders/docker'
    id: 'Push Docker image'
    args:
    - 'push'
    - '--all-tags'
    - 'asia-east1-docker.pkg.dev/bright-gearbox-462803-f5/linebot-repo/linebot'

  # éƒ¨ç½²åˆ° Cloud Run
  - name: 'gcr.io/google.com/cloudsdktool/cloud-sdk'
    id: 'Deploy to Cloud Run'
    entrypoint: 'sh'
    args:
    - '-c'
    - |
      SHORT_SHA=$(cat /workspace/short_sha.txt)
      gcloud run deploy linebot \
        --image asia-east1-docker.pkg.dev/bright-gearbox-462803-f5/linebot-repo/linebot:$SHORT_SHA \
        --region asia-east1 \
        --platform managed \
        --allow-unauthenticated \
        --service-account 487710707313-compute@developer.gserviceaccount.com \
        --min-instances 1 \
        --max-instances 10 \
        --memory 2Gi \
        --cpu 2 \
        --timeout 300 \
        --concurrency 50 \
        --set-env-vars "SHEET_ID=1_4R_ftouDHhUXygW3ab7YlEzLWbXytwudfOegUIhu5Y,MODEL_NAME=gpt-4o,MODEL_EMBED=text-embedding-3-large,CONTEXT_K=5,FAQ_CACHE_TTL=3600,SIM_THRESHOLD=0.50,VECTOR_SIM_THRESHOLD=0.60,WEIGHT_PRIORITY=0.10,MODEL_TEMPERATURE=0.85" \
        --set-secrets "LINE_CHANNEL_ACCESS_TOKEN=line-channel-access-token:latest,LINE_CHANNEL_SECRET=line-channel-secret:latest,OPENAI_API_KEY=openai-api-key:latest"

options:
  logging: CLOUD_LOGGING_ONLY
```

### Cloud Run æœå‹™é…ç½®

#### service.yaml ç¯„ä¾‹
```yaml
apiVersion: serving.knative.dev/v1
kind: Service
metadata:
  name: linebot
spec:
  template:
    metadata:
      annotations:
        autoscaling.knative.dev/maxScale: "10"
        autoscaling.knative.dev/minScale: "1"
    spec:
      serviceAccountName: 487710707313-compute@developer.gserviceaccount.com
      containers:
        - image: asia-east1-docker.pkg.dev/bright-gearbox-462803-f5/linebot-repo/linebot:latest
          ports:
            - containerPort: 8080
          env:
            # å¾ Secret Manager æ³¨å…¥
            - name: LINE_CHANNEL_ACCESS_TOKEN
              valueFrom:
                secretKeyRef:
                  name: line-channel-access-token
                  key: "latest"
            - name: LINE_CHANNEL_SECRET
              valueFrom:
                secretKeyRef:
                  name: line-channel-secret
                  key: "latest"
            - name: OPENAI_API_KEY
              valueFrom:
                secretKeyRef:
                  name: openai-api-key
                  key: "latest"
            # ç›´æ¥è¨­å®šçš„ç’°å¢ƒè®Šæ•¸
            - name: SHEET_ID
              value: "1_4R_ftouDHhUXygW3ab7YlEzLWbXytwudfOegUIhu5Y"
            - name: MODEL_NAME
              value: "gpt-4o"
            - name: MODEL_TEMPERATURE
              value: "0.85"
          resources:
            limits:
              memory: 2Gi
              cpu: "2"
      timeoutSeconds: 300
```

### ç‰ˆæœ¬ç®¡ç†ç­–ç•¥

#### Git å·¥ä½œæµç¨‹
```bash
# ä¸»è¦åˆ†æ”¯
main          # ç”Ÿç”¢ç’°å¢ƒ
develop       # é–‹ç™¼ç’°å¢ƒ 
feature/*     # åŠŸèƒ½é–‹ç™¼åˆ†æ”¯
hotfix/*      # ç·Šæ€¥ä¿®å¾©åˆ†æ”¯

# æ¨™ç±¤ç­–ç•¥
v3.0.0        # ä¸»ç‰ˆæœ¬
v3.0.1        # ä¿®æ­£ç‰ˆæœ¬
v3.1.0        # åŠŸèƒ½ç‰ˆæœ¬
```

#### éƒ¨ç½²ç­–ç•¥
```yaml
éƒ¨ç½²æµç¨‹:
1. åŠŸèƒ½é–‹ç™¼ â†’ feature åˆ†æ”¯
2. æ¸¬è©¦å®Œæˆ â†’ åˆä½µåˆ° develop
3. ç©©å®šé©—è­‰ â†’ åˆä½µåˆ° main
4. è‡ªå‹•éƒ¨ç½² â†’ Cloud Run ç”Ÿç”¢ç’°å¢ƒ

å›é€€ç­–ç•¥:
1. ä¿ç•™å‰ä¸€ç‰ˆæœ¬æ˜ åƒ
2. ä¸€éµå›é€€åŠŸèƒ½
3. è³‡æ–™åº«å…¼å®¹æ€§æª¢æŸ¥
```

---

## é–‹ç™¼ç’°å¢ƒè¨­å®š

### æœ¬åœ°é–‹ç™¼ç’°å¢ƒ

#### å¿…è¦è»Ÿé«”å®‰è£
```bash
# Python ç’°å¢ƒ
Python 3.11+
pip (æœ€æ–°ç‰ˆ)

# Google Cloud SDK
curl https://sdk.cloud.google.com | bash
gcloud init
gcloud auth application-default login

# Docker (å¯é¸ï¼Œç”¨æ–¼æœ¬åœ°å®¹å™¨æ¸¬è©¦)
Docker Desktop
```

#### å°ˆæ¡ˆè¨­å®š
```bash
# 1. å…‹éš†å°ˆæ¡ˆ
git clone https://github.com/matt0taiwan/sibyl-ai-linebot
cd sibyl-ai-linebot

# 2. å»ºç«‹è™›æ“¬ç’°å¢ƒ
python -m venv venv
source venv/bin/activate  # Linux/Mac
# æˆ– venv\Scripts\activate  # Windows

# 3. å®‰è£ä¾è³´
pip install -r requirements.txt

# 4. è¨­å®šç’°å¢ƒè®Šæ•¸
cp .env.example .env
# ç·¨è¼¯ .env å¡«å…¥å¿…è¦çš„é‡‘é‘°
```

#### .env ç¯„ä¾‹æª”æ¡ˆ
```bash
# .env.example
# LINE Bot è¨­å®š
LINE_CHANNEL_ACCESS_TOKEN=your_line_channel_access_token
LINE_CHANNEL_SECRET=your_line_channel_secret

# OpenAI è¨­å®š
OPENAI_API_KEY=your_openai_api_key

# Google Sheets è¨­å®š
SHEET_ID=1_4R_ftouDHhUXygW3ab7YlEzLWbXytwudfOegUIhu5Y

# AI æ¨¡å‹è¨­å®š
MODEL_NAME=gpt-4o
MODEL_EMBED=text-embedding-3-large
MODEL_TEMPERATURE=0.85

# æª¢ç´¢åƒæ•¸
CONTEXT_K=5
SIM_THRESHOLD=0.50
VECTOR_SIM_THRESHOLD=0.60
WEIGHT_PRIORITY=0.10

# å¿«å–è¨­å®š
FAQ_CACHE_TTL=3600

# é–‹ç™¼æ¨¡å¼è¨­å®š
DEBUG=true
LOG_LEVEL=INFO
```

### æœ¬åœ°æ¸¬è©¦å·¥å…·

#### ngrok è¨­å®š (ç”¨æ–¼ LINE Webhook æ¸¬è©¦)
```bash
# å®‰è£ ngrok
brew install ngrok  # Mac
# æˆ–ä¸‹è¼‰ https://ngrok.com/download

# å•Ÿå‹•æœ¬åœ°ä¼ºæœå™¨
uvicorn app.main:app --host 0.0.0.0 --port 8080 --reload

# å¦ä¸€å€‹çµ‚ç«¯é–‹å•Ÿ tunnel
ngrok http 8080

# å°‡ ngrok URL è¨­å®šåˆ° LINE Developer Console
# ä¾‹å¦‚: https://abc123.ngrok.io/webhook
```

#### å–®å…ƒæ¸¬è©¦è¨­å®š
```bash
# å®‰è£æ¸¬è©¦ä¾è³´
pip install pytest pytest-asyncio pytest-mock

# åŸ·è¡Œæ¸¬è©¦
pytest tests/ -v

# æ¸¬è©¦è¦†è“‹ç‡
pip install pytest-cov
pytest tests/ --cov=app --cov-report=html
```

### IDE é…ç½®å»ºè­°

#### VSCode è¨­å®š
```json
// .vscode/settings.json
{
    "python.defaultInterpreterPath": "./venv/bin/python",
    "python.linting.enabled": true,
    "python.linting.flake8Enabled": true,
    "python.formatting.provider": "black",
    "python.sortImports.args": ["--profile", "black"],
    "[python]": {
        "editor.formatOnSave": true,
        "editor.codeActionsOnSave": {
            "source.organizeImports": true
        }
    }
}
```

#### æ¨è–¦æ“´å……å¥—ä»¶
```json
// .vscode/extensions.json
{
    "recommendations": [
        "ms-python.python",
        "ms-python.flake8",
        "ms-python.black-formatter",
        "ms-python.isort",
        "bradlc.vscode-tailwindcss",
        "ms-vscode.vscode-json"
    ]
}
```

---

## ç¨‹å¼ç¢¼è¦ç¯„

### Python ç·¨ç¢¼æ¨™æº–

#### PEP 8 åˆè¦æ€§
```python
# è¡Œé•·åº¦é™åˆ¶
æœ€å¤§è¡Œé•·åº¦: 88 å­—å…ƒ (Black formatter é è¨­)

# å‘½åè¦ç¯„
å‡½æ•¸åç¨±: snake_case
é¡åˆ¥åç¨±: PascalCase
å¸¸æ•¸åç¨±: UPPER_SNAKE_CASE
è®Šæ•¸åç¨±: snake_case
ç§æœ‰æ–¹æ³•: _leading_underscore

# ç¯„ä¾‹
class MessageProcessor:
    """è¨Šæ¯è™•ç†å™¨é¡åˆ¥"""
    
    MAX_RETRY_COUNT = 3
    
    def __init__(self):
        self.retry_count = 0
        self._private_method()
    
    def process_message(self, user_message: str) -> str:
        """è™•ç†ç”¨æˆ¶è¨Šæ¯"""
        return self._generate_response(user_message)
    
    def _generate_response(self, message: str) -> str:
        """ç§æœ‰æ–¹æ³•ï¼šç”Ÿæˆå›æ‡‰"""
        pass
```

#### é¡å‹æç¤ºè¦ç¯„
```python
from typing import Dict, List, Optional, Union, Tuple, Any
from dataclasses import dataclass
from datetime import datetime

# å‡½æ•¸é¡å‹æç¤º
def process_intent(
    user_id: str,
    message: str,
    context: Optional[Dict[str, Any]] = None
) -> Tuple[str, float]:
    """
    è™•ç†ç”¨æˆ¶æ„åœ–
    
    Args:
        user_id: ç”¨æˆ¶å”¯ä¸€è­˜åˆ¥ç¢¼
        message: ç”¨æˆ¶è¨Šæ¯å…§å®¹
        context: å¯é¸çš„ä¸Šä¸‹æ–‡è³‡è¨Š
        
    Returns:
        Tuple[str, float]: (è­˜åˆ¥çš„æ„åœ–, ä¿¡å¿ƒåº¦åˆ†æ•¸)
    """
    pass

# è³‡æ–™é¡åˆ¥å®šç¾©
@dataclass
class ConversationState:
    user_id: str
    current_step: int
    collected_data: Dict[str, Any]
    started_at: datetime
    expires_at: datetime
```

#### æ–‡æª”å­—ä¸²æ¨™æº–
```python
def calculate_similarity(text1: str, text2: str) -> float:
    """
    è¨ˆç®—å…©å€‹æ–‡å­—ä¹‹é–“çš„ç›¸ä¼¼åº¦
    
    ä½¿ç”¨ Levenshtein è·é›¢ç®—æ³•è¨ˆç®—æ–‡å­—ç›¸ä¼¼åº¦ï¼Œ
    è¿”å› 0.0 åˆ° 1.0 ä¹‹é–“çš„ç›¸ä¼¼åº¦åˆ†æ•¸ã€‚
    
    Args:
        text1 (str): ç¬¬ä¸€å€‹æ¯”è¼ƒæ–‡å­—
        text2 (str): ç¬¬äºŒå€‹æ¯”è¼ƒæ–‡å­—
        
    Returns:
        float: ç›¸ä¼¼åº¦åˆ†æ•¸ï¼Œ1.0 è¡¨ç¤ºå®Œå…¨ç›¸åŒï¼Œ0.0 è¡¨ç¤ºå®Œå…¨ä¸åŒ
        
    Example:
        >>> calculate_similarity("hello", "hello")
        1.0
        >>> calculate_similarity("hello", "world")
        0.2
        
    Raises:
        ValueError: ç•¶è¼¸å…¥ç‚ºç©ºå­—ä¸²æ™‚
    """
    if not text1 or not text2:
        raise ValueError("è¼¸å…¥æ–‡å­—ä¸èƒ½ç‚ºç©º")
    
    # å¯¦ä½œé‚è¼¯...
    pass
```

### éŒ¯èª¤è™•ç†æ¨™æº–

#### ç•°å¸¸è™•ç†æ¨¡å¼
```python
import logging
from typing import Optional

logger = logging.getLogger(__name__)

class SibylError(Exception):
    """Sibyl AI åŸºç¤ç•°å¸¸é¡åˆ¥"""
    pass

class OpenAIError(SibylError):
    """OpenAI API ç›¸é—œéŒ¯èª¤"""
    pass

class FirestoreError(SibylError):
    """Firestore ç›¸é—œéŒ¯èª¤"""
    pass

# éŒ¯èª¤è™•ç†ç¯„ä¾‹
async def call_openai_api(prompt: str) -> Optional[str]:
    """èª¿ç”¨ OpenAI API ä¸¦è™•ç†éŒ¯èª¤"""
    try:
        response = openai_client.chat.completions.create(
            model=MODEL_NAME,
            messages=[{"role": "user", "content": prompt}],
            temperature=MODEL_TEMPERATURE
        )
        return response.choices[0].message.content
        
    except openai.RateLimitError as e:
        logger.warning(f"OpenAI rate limit exceeded: {e}")
        # å¯¦ä½œæŒ‡æ•¸é€€é¿é‡è©¦
        await asyncio.sleep(2 ** retry_count)
        raise OpenAIError("API èª¿ç”¨é »ç‡é™åˆ¶")
        
    except openai.APIError as e:
        logger.error(f"OpenAI API error: {e}")
        raise OpenAIError(f"API éŒ¯èª¤: {e}")
        
    except Exception as e:
        logger.error(f"Unexpected error calling OpenAI: {e}", exc_info=True)
        raise SibylError("æœªé æœŸçš„éŒ¯èª¤")
```

#### æ—¥èªŒè¨˜éŒ„æ¨™æº–
```python
import logging
from datetime import datetime

# æ—¥èªŒé…ç½®
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    handlers=[
        logging.StreamHandler(),
        logging.FileHandler('sibyl.log')
    ]
)

logger = logging.getLogger(__name__)

# æ—¥èªŒä½¿ç”¨ç¯„ä¾‹
def process_user_message(user_id: str, message: str):
    """è™•ç†ç”¨æˆ¶è¨Šæ¯ä¸¦è¨˜éŒ„æ—¥èªŒ"""
    logger.info(f"Processing message from user {user_id}")
    
    try:
        # è™•ç†é‚è¼¯
        result = handle_message(message)
        logger.info(f"Successfully processed message for user {user_id}")
        return result
        
    except Exception as e:
        logger.error(f"Error processing message for user {user_id}: {e}", exc_info=True)
        raise

# æ•ˆèƒ½ç›£æ§æ—¥èªŒ
def log_performance(func_name: str, duration_ms: int, user_id: str = None):
    """è¨˜éŒ„æ•ˆèƒ½æŒ‡æ¨™"""
    logger.info(f"Performance: {func_name} took {duration_ms}ms", extra={
        'function': func_name,
        'duration_ms': duration_ms,
        'user_id': user_id,
        'timestamp': datetime.now().isoformat()
    })
```

### æ¸¬è©¦æ¨™æº–

#### å–®å…ƒæ¸¬è©¦çµæ§‹
```python
# tests/test_intent_classifier.py
import pytest
import asyncio
from unittest.mock import Mock, patch
from app.intent_classifier import LLMIntentClassifier, IntentType

class TestLLMIntentClassifier:
    """æ„åœ–åˆ†é¡å™¨æ¸¬è©¦"""
    
    @pytest.fixture
    def classifier(self):
        """æ¸¬è©¦ç”¨åˆ†é¡å™¨å¯¦ä¾‹"""
        return LLMIntentClassifier()
    
    @pytest.mark.asyncio
    async def test_price_inquiry_classification(self, classifier):
        """æ¸¬è©¦åƒ¹æ ¼è©¢å•æ„åœ–è­˜åˆ¥"""
        # Arrange
        user_message = "å¡”ä½åƒ¹æ ¼å¤šå°‘éŒ¢ï¼Ÿ"
        
        # Mock OpenAI response
        mock_response = {
            "intent": "price_inquiry",
            "confidence": 0.95,
            "extracted_data": {},
            "need_human": False,
            "reason": "æ˜ç¢ºçš„åƒ¹æ ¼è©¢å•"
        }
        
        with patch('app.config.openai_client.chat.completions.create') as mock_openai:
            mock_openai.return_value.choices[0].message.content = json.dumps(mock_response)
            
            # Act
            result = await classifier.classify(user_message)
            
            # Assert
            assert result.primary_intent == IntentType.PRICE_INQUIRY
            assert result.confidence == 0.95
            assert not result.need_human
    
    @pytest.mark.asyncio
    async def test_openai_api_failure(self, classifier):
        """æ¸¬è©¦ OpenAI API å¤±æ•—è™•ç†"""
        with patch('app.config.openai_client.chat.completions.create') as mock_openai:
            mock_openai.side_effect = Exception("API Error")
            
            result = await classifier.classify("æ¸¬è©¦è¨Šæ¯")
            
            # æ‡‰è©²å›é€€åˆ°ä¸€èˆ¬è«®è©¢
            assert result.primary_intent == IntentType.GENERAL_INQUIRY
            assert result.need_human == True
```

#### æ•´åˆæ¸¬è©¦ç¯„ä¾‹
```python
# tests/test_integration.py
import pytest
from fastapi.testclient import TestClient
from app.main import app

class TestWebhookIntegration:
    """Webhook æ•´åˆæ¸¬è©¦"""
    
    @pytest.fixture
    def client(self):
        return TestClient(app)
    
    def test_health_check(self, client):
        """æ¸¬è©¦å¥åº·æª¢æŸ¥ç«¯é»"""
        response = client.get("/health")
        assert response.status_code == 200
        assert response.json()["status"] in ["healthy", "degraded"]
    
    def test_webhook_signature_validation(self, client):
        """æ¸¬è©¦ Webhook ç°½åé©—è­‰"""
        # ç„¡æ•ˆç°½åæ‡‰è©²è¢«æ‹’çµ•
        response = client.post("/webhook", 
                             headers={"X-Line-Signature": "invalid"},
                             json={"events": []})
        assert response.status_code == 403
```

---

## é‹ç¶­ç›£æ§

### ç›£æ§æŒ‡æ¨™è¨­è¨ˆ

#### ç³»çµ±å¥åº·æŒ‡æ¨™
```python
# app/monitoring.py
from prometheus_client import Counter, Histogram, Gauge
import time
import functools

# æŒ‡æ¨™å®šç¾©
REQUEST_COUNT = Counter('sibyl_requests_total', 'Total requests', ['method', 'endpoint'])
REQUEST_DURATION = Histogram('sibyl_request_duration_seconds', 'Request duration')
ACTIVE_CONVERSATIONS = Gauge('sibyl_active_conversations', 'Active conversations')
OPENAI_API_CALLS = Counter('sibyl_openai_calls_total', 'OpenAI API calls', ['model'])
OPENAI_TOKEN_USAGE = Counter('sibyl_openai_tokens_total', 'OpenAI tokens used', ['type'])

# ç›£æ§è£é£¾å™¨
def monitor_performance(func):
    """ç›£æ§å‡½æ•¸åŸ·è¡Œæ•ˆèƒ½"""
    @functools.wraps(func)
    async def wrapper(*args, **kwargs):
        start_time = time.time()
        try:
            result = await func(*args, **kwargs)
            return result
        finally:
            duration = time.time() - start_time
            REQUEST_DURATION.observe(duration)
            
            # è¨˜éŒ„æ•ˆèƒ½æ—¥èªŒ
            if duration > 5.0:  # è¶…é 5 ç§’è¨˜éŒ„è­¦å‘Š
                logger.warning(f"Slow function {func.__name__}: {duration:.2f}s")
    
    return wrapper

# ä½¿ç”¨ç¯„ä¾‹
@monitor_performance
async def process_message(user_id: str, message: str):
    """è¢«ç›£æ§çš„è¨Šæ¯è™•ç†å‡½æ•¸"""
    REQUEST_COUNT.labels(method='process', endpoint='message').inc()
    # è™•ç†é‚è¼¯...
```

#### æ¥­å‹™æŒ‡æ¨™ç›£æ§
```python
# æ¥­å‹™æŒ‡æ¨™æ”¶é›†
class BusinessMetrics:
    def __init__(self):
        self.intent_accuracy = Histogram('sibyl_intent_accuracy', 'Intent classification accuracy')
        self.conversation_completion = Counter('sibyl_conversations_completed', 'Completed conversations')
        self.human_handover = Counter('sibyl_human_handover', 'Human handover events', ['reason'])
        self.faq_hit_rate = Histogram('sibyl_faq_hit_rate', 'FAQ hit rate')
    
    def record_intent_classification(self, confidence: float):
        """è¨˜éŒ„æ„åœ–è­˜åˆ¥æº–ç¢ºåº¦"""
        self.intent_accuracy.observe(confidence)
    
    def record_conversation_completion(self, intent_type: str):
        """è¨˜éŒ„å°è©±å®Œæˆ"""
        self.conversation_completion.labels(intent=intent_type).inc()
    
    def record_human_handover(self, reason: str):
        """è¨˜éŒ„äººå·¥æ¥ç®¡"""
        self.human_handover.labels(reason=reason).inc()

business_metrics = BusinessMetrics()
```

### æ—¥èªŒèšåˆèˆ‡åˆ†æ

#### çµæ§‹åŒ–æ—¥èªŒ
```python
import json
import logging
from datetime import datetime

class JSONFormatter(logging.Formatter):
    """JSON æ ¼å¼æ—¥èªŒ"""
    
    def format(self, record):
        log_entry = {
            'timestamp': datetime.utcnow().isoformat(),
            'level': record.levelname,
            'logger': record.name,
            'message': record.getMessage(),
            'module': record.module,
            'function': record.funcName,
            'line': record.lineno
        }
        
        # æ·»åŠ é¡å¤–å­—æ®µ
        if hasattr(record, 'user_id'):
            log_entry['user_id'] = record.user_id
        if hasattr(record, 'request_id'):
            log_entry['request_id'] = record.request_id
        if hasattr(record, 'duration_ms'):
            log_entry['duration_ms'] = record.duration_ms
            
        return json.dumps(log_entry, ensure_ascii=False)

# é…ç½®çµæ§‹åŒ–æ—¥èªŒ
def setup_logging():
    """è¨­å®šçµæ§‹åŒ–æ—¥èªŒ"""
    logger = logging.getLogger()
    handler = logging.StreamHandler()
    handler.setFormatter(JSONFormatter())
    logger.addHandler(handler)
    logger.setLevel(logging.INFO)

# ä½¿ç”¨ç¯„ä¾‹
logger = logging.getLogger(__name__)

def log_user_interaction(user_id: str, action: str, duration_ms: int):
    """è¨˜éŒ„ç”¨æˆ¶äº’å‹•"""
    logger.info(f"User interaction: {action}", extra={
        'user_id': user_id,
        'action': action,
        'duration_ms': duration_ms
    })
```

#### Cloud Logging æ•´åˆ
```python
# Google Cloud Logging è¨­å®š
from google.cloud import logging as cloud_logging

def setup_cloud_logging():
    """è¨­å®š Google Cloud Logging"""
    client = cloud_logging.Client()
    client.setup_logging()
    
    # è‡ªè¨‚æ—¥èªŒè™•ç†
    cloud_handler = cloud_logging.handlers.CloudLoggingHandler(client)
    cloud_handler.setFormatter(JSONFormatter())
    
    logger = logging.getLogger()
    logger.addHandler(cloud_handler)
```

### å‘Šè­¦èˆ‡é€šçŸ¥

#### å‘Šè­¦è¦å‰‡å®šç¾©
```python
# app/alerting.py
import smtplib
from email.mime.text import MIMEText
from datetime import datetime, timedelta

class AlertManager:
    def __init__(self):
        self.alert_thresholds = {
            'error_rate': 0.05,        # 5% éŒ¯èª¤ç‡
            'response_time': 10.0,     # 10ç§’å›æ‡‰æ™‚é–“
            'memory_usage': 0.90,      # 90% è¨˜æ†¶é«”ä½¿ç”¨ç‡
            'openai_failures': 5       # 5æ¬¡ OpenAI å¤±æ•—
        }
        self.alert_intervals = {}  # é˜²æ­¢é‡è¤‡å‘Šè­¦
    
    def check_error_rate(self, error_count: int, total_count: int):
        """æª¢æŸ¥éŒ¯èª¤ç‡"""
        if total_count == 0:
            return
            
        error_rate = error_count / total_count
        if error_rate > self.alert_thresholds['error_rate']:
            self.send_alert(
                'High Error Rate',
                f'Error rate: {error_rate:.2%} (threshold: {self.alert_thresholds["error_rate"]:.2%})'
            )
    
    def check_response_time(self, avg_response_time: float):
        """æª¢æŸ¥å›æ‡‰æ™‚é–“"""
        if avg_response_time > self.alert_thresholds['response_time']:
            self.send_alert(
                'Slow Response Time',
                f'Average response time: {avg_response_time:.2f}s'
            )
    
    def send_alert(self, title: str, message: str):
        """ç™¼é€å‘Šè­¦é€šçŸ¥"""
        # æª¢æŸ¥å‘Šè­¦é–“éš”ï¼Œé¿å…é‡è¤‡ç™¼é€
        alert_key = f"{title}_{datetime.now().strftime('%Y%m%d%H')}"  # æ¯å°æ™‚æœ€å¤šä¸€æ¬¡
        
        if alert_key in self.alert_intervals:
            return
            
        self.alert_intervals[alert_key] = datetime.now()
        
        # ç™¼é€å‘Šè­¦ (å¯ä»¥æ˜¯ email, Slack, ç­‰)
        self._send_email_alert(title, message)
        logger.error(f"ALERT: {title} - {message}")
    
    def _send_email_alert(self, title: str, message: str):
        """ç™¼é€ email å‘Šè­¦"""
        # å¯¦ä½œ email ç™¼é€é‚è¼¯
        pass

alert_manager = AlertManager()
```

### æ•ˆèƒ½ç›£æ§å„€è¡¨æ¿

#### Grafana Dashboard é…ç½®
```json
{
  "dashboard": {
    "title": "Sibyl AI Monitoring",
    "panels": [
      {
        "title": "Request Rate",
        "type": "graph",
        "targets": [
          {
            "expr": "rate(sibyl_requests_total[5m])",
            "legendFormat": "{{method}} {{endpoint}}"
          }
        ]
      },
      {
        "title": "Response Time",
        "type": "graph",
        "targets": [
          {
            "expr": "histogram_quantile(0.95, rate(sibyl_request_duration_seconds_bucket[5m]))",
            "legendFormat": "95th percentile"
          }
        ]
      },
      {
        "title": "

## æœ€æ–°æ›´æ–° (2025-07-18)

### é˜²æ¿«ç”¨æ©Ÿåˆ¶å¯¦ä½œ
- **AI ä½¿ç”¨é‡é™åˆ¶**ï¼šæ¯ç”¨æˆ¶æ¯æ—¥ 100 æ¬¡ AI å°è©±é™åˆ¶
- **æ™‚å€è™•ç†**ï¼šä½¿ç”¨å°ç£æ™‚å€ï¼ˆUTC+8ï¼‰è¨ˆç®—æ¯æ—¥é™åˆ¶ï¼Œåˆå¤œé‡ç½®
- **è³‡æ–™å„²å­˜**ï¼šä½¿ç”¨ Firestore é›†åˆ `user_ai_usage` å„²å­˜ä½¿ç”¨è¨˜éŒ„
- **è‡ªå‹•æ¸…ç†**ï¼šè¶…é 7 å¤©çš„ä½¿ç”¨è¨˜éŒ„è‡ªå‹•åˆªé™¤
- **éŒ¯èª¤è™•ç†**ï¼šå¦‚æª¢æŸ¥å¤±æ•—é è¨­å…è¨±ä½¿ç”¨ï¼Œé¿å…å½±éŸ¿æœå‹™
- **äº¤æ˜“æ”¯æ´**ï¼šä½¿ç”¨ Firestore transaction ç¢ºä¿è¨ˆæ•¸æº–ç¢ºæ€§

### å¯¦ä½œç´°ç¯€
- **memory_manager.py**ï¼š
  - `check_ai_usage_limit()` - æª¢æŸ¥ç”¨æˆ¶ä»Šæ—¥ä½¿ç”¨é‡
  - `increment_ai_usage()` - å¢åŠ ä½¿ç”¨æ¬¡æ•¸
  - `_get_today_key()` - å–å¾—å°ç£æ™‚å€æ—¥æœŸ
  - `_cleanup_old_usage()` - æ¸…ç†èˆŠè¨˜éŒ„
- **message_processor.py**ï¼š
  - åœ¨ AI æ¨¡å¼è™•ç†å‰æª¢æŸ¥é™åˆ¶
  - é”åˆ°é™åˆ¶æ™‚é¡¯ç¤ºå‹å–„æç¤º
- **å®¢æœè³‡è¨Šæ›´æ–°**ï¼š
  - å°ˆç·šï¼š04-25376688
  - æ™‚é–“ï¼š09:00-17:00

## ä¹‹å‰æ›´æ–° (2025-07-17)

### æ¥­å‹™é‚è¼¯å„ªåŒ– - æ¢ä»¶æ€§æ¬„ä½å¯¦ä½œ
- **å‹•æ…‹æ¬„ä½æ”¶é›†**ï¼šæ ¹æ“šç”¨æˆ¶é¸æ“‡å‹•æ…‹èª¿æ•´éœ€è¦æ”¶é›†çš„æ¬„ä½
- **æ¢ä»¶æ€§æ¬„ä½æ¶æ§‹**ï¼š
  - æ³•æœƒå ±åï¼ˆæ‹œæ¡Œï¼‰ï¼šæ–°å¢è™•ç†æ–¹å¼é¸é …ï¼ˆä»£æ/è‡ªå–/è¨—é‹[éš±è—]ï¼‰
  - ä½›äº‹ç™»è¨˜ï¼ˆå°å¹´ï¼‰ï¼šæ–°å¢ä¸‰é¸é …ï¼ˆå–®ç´”èª¦ç¶“/è«‹é¦™ç«å›å®¶/å¡”ä¸Šåˆçˆï¼‰
  - è¨—é‹é¸é …ï¼šä¸ä¸»å‹•é¡¯ç¤ºï¼Œä½†ç•¶ç”¨æˆ¶æåˆ°è¨—é‹ç›¸é—œé—œéµå­—æ™‚è‡ªå‹•è­˜åˆ¥ä¸¦è™•ç†
- **è¨—é‹è³‡è¨Šæ”¶é›†**ï¼šç•¶é¸æ“‡è¨—é‹æ™‚ï¼Œå‹•æ…‹æ–°å¢æ”¶ä»¶äººã€æ”¶ä»¶äººé›»è©±ã€æ”¶ä»¶åœ°å€æ¬„ä½

### æ™ºæ…§è³‡æ–™æ“·å–å¼·åŒ–
- **SmartDataExtractor æ“´å……**ï¼šæå–æ¢ä»¶æ€§æ¬„ä½ï¼ˆæ‹œæ¡Œè™•ç†æ–¹å¼ã€å°å¹´è™•ç†æ–¹å¼ï¼‰
- **æ¬„ä½é å¡«å……**ï¼šå¾å–®ä¸€è¨Šæ¯ä¸­æå–å¤šå€‹æ¬„ä½ï¼Œæ¸›å°‘å°è©±è¼ªæ¬¡
- **åŒä¸ŠåŠŸèƒ½**ï¼šè¨—é‹è³‡è¨Šæ”¯æ´ã€ŒåŒä¸Šã€å¿«é€Ÿå¡«å¯«ï¼Œè‡ªå‹•ä½¿ç”¨å ±åè³‡è¨Š

### å³æ™‚æ¬„ä½é©—è­‰ç³»çµ±
- **æ–°æ¨¡çµ„ field_validator.py**ï¼š
  - é›»è©±è™Ÿç¢¼æ ¼å¼é©—è­‰ï¼ˆæ‰‹æ©Ÿã€å¸‚è©±ï¼‰
  - æ—¥æœŸæ™‚é–“æ ¼å¼é©—è­‰ï¼ˆæ”¯æ´å¤šç¨®æ ¼å¼ï¼‰
  - åœ°å€å®Œæ•´æ€§é©—è­‰
  - é¸é …æœ‰æ•ˆæ€§é©—è­‰ï¼ˆæ‹œæ¡Œè™•ç†ã€å°å¹´è™•ç†ï¼‰
- **éŒ¯èª¤æç¤ºå‹å–„åŒ–**ï¼šæä¾›å…·é«”çš„æ ¼å¼ç¯„ä¾‹å’Œä¿®æ­£å»ºè­°
- **éš±è—é¸é …è™•ç†**ï¼šè¨—é‹é¸é …çš„æ™ºæ…§è­˜åˆ¥ï¼ˆä¸é¡¯ç¤ºä½†å¯è­˜åˆ¥ï¼‰

### æµç¨‹é€²åº¦è¦–è¦ºåŒ–
- **æ–°æ¨¡çµ„ progress_formatter.py**ï¼š
  - å‹•æ…‹é€²åº¦æ¢é¡¯ç¤ºï¼ˆæ ¹æ“šæ¢ä»¶æ€§æ¬„ä½èª¿æ•´ç¸½æ•¸ï¼‰
  - å·²å¡«/å¾…å¡«æ¬„ä½æ¸…å–®
  - éŒ¯èª¤æ™‚é¡¯ç¤ºé€²åº¦ä¸Šä¸‹æ–‡
  - å®Œæˆæ‘˜è¦æ ¼å¼åŒ–ï¼ˆè¨—é‹è³‡è¨Šé¡¯ç¤ºåœ¨æœ€å¾Œï¼‰
- **è¦–è¦ºå…ƒç´ **ï¼šä½¿ç”¨ emoji å¢å¼·å¯è®€æ€§ï¼ˆâœ… å·²å®Œæˆã€ğŸ‘‰ ç•¶å‰ã€â³ å¾…å¡«å¯«ï¼‰

### ç¨‹å¼ç¢¼æ¶æ§‹å„ªåŒ–
- **ConversationState å¢å¼·**ï¼š
  - æ–°å¢ `conditional_fields` çµæ§‹å®šç¾©æ¢ä»¶é‚è¼¯
  - å¯¦ä½œ `get_dynamic_fields()` å‹•æ…‹è¨ˆç®—æ¬„ä½åˆ—è¡¨
  - å¯¦ä½œ `get_next_field()` æ™ºæ…§å–å¾—ä¸‹ä¸€å€‹æ¬„ä½
- **FlowHandler æ•´åˆ**ï¼šç„¡ç¸«æ•´åˆé©—è­‰å™¨å’Œé€²åº¦æ ¼å¼åŒ–å™¨
- **ç‹€æ…‹ç®¡ç†æ”¹é€²**ï¼šæ”¯æ´è¤‡é›œçš„å¤šå±¤æ¢ä»¶æ¬„ä½é‚è¼¯

## ä¹‹å‰æ›´æ–° (2025-07-16)

### AI å°è©±æ™ºæ…§æå‡
- **æ„åœ–ç³¾æ­£è™•ç†**ï¼šä¿®å¾©ç”¨æˆ¶å¦å®šæ„åœ–ï¼ˆå¦‚ã€Œæˆ‘æ²’æœ‰è¦é ç´„ã€ï¼‰å¾Œ AI åœæ­¢å›æ‡‰çš„å•é¡Œ
- **äºŒæ¬¡ç¢ºèªæ©Ÿåˆ¶**ï¼šå¯¦ä½œæ„åœ–ç¢ºèªæµç¨‹ï¼Œä½ä¿¡å¿ƒåº¦æˆ–æ¨¡ç³Šè¨Šæ¯æœƒå…ˆç¢ºèªå†é–‹å§‹
- **å¾…ç¢ºèªç‹€æ…‹**ï¼šæ–°å¢ `pending_confirmation` ç‹€æ…‹ç®¡ç†
- **æ™‚é–“æ€§æè¿°**ï¼šæ”¹é€²ã€Œå°å¹´å¿«åˆ°äº†ã€ç­‰æ™‚é–“æ€§è¡¨é”çš„æ„åœ–è­˜åˆ¥

### Template Message ä¿®å¾©èˆ‡å„ªåŒ–
- **ç™¼é€å•é¡Œä¿®å¾©**ï¼šè§£æ±º TemplateMessage é¡å‹å°å…¥å•é¡Œ
- **URL é©—è­‰å¼·åŒ–**ï¼šè‡ªå‹•å°‡ HTTP è½‰æ›ç‚º HTTPSï¼ˆLINE è¦æ±‚ï¼‰
- **éŒ¯èª¤è™•ç†æ”¹é€²**ï¼šå¢åŠ è©³ç´°æ—¥èªŒå’Œå‚™æ´æ©Ÿåˆ¶
- **é™ç´šç­–ç•¥**ï¼šTemplate å»ºç«‹å¤±æ•—æ™‚è‡ªå‹•ä½¿ç”¨ä¸€èˆ¬åœ–ç‰‡è¨Šæ¯

### åƒ¹æ ¼ç®¡ç†ç³»çµ±é©æ–°
- **FAQ åŒ–å¯¦ç¾**ï¼šåƒ¹æ ¼è©¢å•å¾ç¡¬ç·¨ç¢¼æ”¹ç‚º FAQ ç³»çµ±ï¼ˆID: P001ï¼‰
- **æ¥­å‹™ç­–ç•¥ä¿ç•™**ï¼šç¶­æŒã€Œå…ˆåƒ¹å€¼å¾Œåƒ¹æ ¼ã€çš„éŠ·å”®è©±è¡“
- **å‹•æ…‹ç®¡ç†**ï¼šæ¥­å‹™åœ˜éšŠå¯åœ¨ Google Sheets è‡ªè¡Œæ›´æ–°
- **ç®¡ç†æ–‡æª”**ï¼šå»ºç«‹å®Œæ•´çš„åƒ¹æ ¼ FAQ ç®¡ç†æŒ‡å—

### ç¨‹å¼ç¢¼çµæ§‹å„ªåŒ–
- **FlowHandler å¢å¼·**ï¼šæ–°å¢ `_is_ambiguous_message()` å’Œ `_confirm_intent_before_flow()`
- **ConversationState æ“´å……**ï¼šåŠ å…¥ `pending_intent` å’Œ `pending_data` æ¬„ä½
- **éŒ¯èª¤è™•ç†çµ±ä¸€**ï¼šæ‰€æœ‰ Template Message éŒ¯èª¤éƒ½æœ‰è©³ç´°è¨˜éŒ„

## ä¹‹å‰æ›´æ–° (2025-07-15)

### é›™æ¨¡å¼ç³»çµ±å®Œå–„
- **å‚³çµ±æ¨¡å¼**ï¼šç²¾ç¢ºé—œéµå­—åŒ¹é…ï¼Œæ”¯æ´ LINE OA é¢¨æ ¼è‡ªå‹•å›è¦†
- **AI æ¨¡å¼**ï¼šæ™ºæ…§å°è©±ï¼Œæ°¸ä¹…ä¿æŒï¼ˆç§»é™¤ 30 åˆ†é˜è¶…æ™‚ï¼‰
- **æ¨¡å¼åˆ‡æ›**ï¼šæµæš¢åˆ‡æ›ï¼Œç‹€æ…‹æŒä¹…åŒ–æ–¼ Firestore

### AI æ¨¡å¼åˆ‡æ›å¢å¼·
- "0" é—œéµå­—ç¾åœ¨å¯å¾ Google Sheets æ§åˆ¶æ–‡æ¡ˆå…§å®¹
- ç³»çµ±å…ˆæª¢æŸ¥ Sheets è‡ªå‹•å›è¦†ï¼Œå†åŸ·è¡Œæ¨¡å¼åˆ‡æ›
- å…¶ä»– AI åˆ‡æ›é—œéµå­—ä¿æŒé è¨­æ­¡è¿è¨Šæ¯
